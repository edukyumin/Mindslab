# 마인즈랩 적응기

> 혜린매니저:eight_pointed_black_star:님께 배운 모든지식을 정리해놓은 것 입니다. 후대에 널리널리쓰이길 기원합니다.
>
> 작성자: 1급노예 이규민:star:
>
> 업데이트 일자: 2020.10.08

## 

## * STT TTS 정보

> 이 문서의 하이라이트인 STT 와 TTS 전처리,학습,아웃풋 통합 정리본 입니다. 
>
> 이문서와 함께라면 따듯한 마인즈랩 생활이 될 것을 보장합니다.
>
> - TTS STT 공부
>
>   - TTS (컨플루엔스 실무교육 공부하기)
>
>     - `https://pms.maum.ai/`
>
>     - `https://startagainbornagain.tistory.com/28?category=720149`
>
>     - RNN LSTM `https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/`
>
> - Docker 공부해보기
>
>   > 컨플루엔스 - 실무교육 -cli기초 - linux docker 공부하기
>
> - 서버기초교육 3개 다보기 

### :one: STT

> 7번에서진행하세요

#### 전처리

- `Python`을 사용하여 전처리 진행
- 데이터명 통일 전처리 진행
- 기호 삭제 전처리 진행



#### 학습

~~아직 정확하게 해보지 않아서 완벽할 때 업뎃 예정~~



#### 인식률테스트

**아래를 순서대로 진행**

1. 7번서버에서 진행(shell 7번서버 켜기)

2. 수도 안으로 들어온다 
   - `sudo su`
   - id: `minds` pw: `msl1234!`

3. docker의 상태를 확인한다
   - `docker ps`
   - 죽은것까지 보려면 `docker ps -a`
   
4. docker로 들어간다
   - `docker exec -it {도커이름, 예시:w2l-Train-04} /bin/bash`
   - 잘들어왔는지 확인
     - `ll`
   
5. 폴더 이동 
   - `cd DATA`
   - `cd w21_20200318`
   - `cd test`
   - `ll` 찍어보기
   
6. 서버환경 만들기
   - `cd ~/wav2letter/build/`
   - `ll` 찍어보면 Server가 있다.
   - `nohup ./Server -flagfile /DATA/w2l_20200318/test/{원하는 파일: server_kor_hoe.cfg} --port {원하는 포트번호: 12345}`
   - 이때 위의명령어를 치기전에 새로운 shell창을 열어서(서버동일) 포트가 사용중인지 찾아본다
   
7. 새로운창에서(도커밖에서)
   - `sudo su`
   - 서버가 뭐가 켜있는지 확인
     - `ps -ef | grep Server`
     - 이때 켜져잇는게 있다면(쓰려는데 켜져잇다면)
       - kill -9 {켜져잇는 포트의 맨앞에 있는숫자 예시: 17459}
   
8. 다시 docker 창으로 돌아와서 명령어 실행
   - 포트연결하기
     - `nohup ./Server -flagfile /DATA/w2l_20200318/test/{원하는 파일: server_kor_hoe.cfg} --port {원하는 포트번호: 12345} --logtostderr=1 &`
   
9. `ll` 찍어보고

10. batch_client.py 파이썬 파일실행
    - `python batch_client.py -i {정제데이터 있는 경로: /DATA/w2l_20200318/test/testdata_edulab2} -o {정제데이터 아웃풋 생기는 경로: /DATA/w2l_20200318/test/edulab_hoe} -e euc-kr`
      - 위의 명령어 실행하다 오류생겻엇으니 파일경로같은거 잘 확인하기
    
11. 위의 결과물이 생성되었다면 result생성된 디렉토리로 이동(여기서부턴 도커 밖에서 한다)
    
    - `/data1/minds/TEST/` 어딘가에 생겻을걸 (아마)
    
12. 인코딩을 변경해준다
    
    - `python iconv_file.py -sf utf-8 -cf euc-kr -d ./{디렉토리명: 11번에서의 디렉토리를 의미}`
    
13. 디렉토리명에 들어간 후 
    - `cd iconv_output`
    - `file *.txt` 명령어를 통해 txt파일들이 잘 인코딩되었는지 확인
    - `file *.result` 명령어를 통해 result 파일들이 잘 인코딩되었는지 확인 
    
14. txt, result 파일이 다 인코딩 완벽하다면 한단계바깥(원본이있는)에 인코딩된 파일들로 덮어씌워준다!
    - `mv *.txt ../`
    - `mv *.result ../`
    
15. iconv_output 폴더 삭제

16. `cd data1/minds/TEST`

17. `.do_evaluation.sh {13~15의 디렉토리명}`

18. 잘됐다면 다음의 창이 나온다

    - ![image](https://user-images.githubusercontent.com/60081254/95424443-99278c80-097d-11eb-8c1c-53370af7d823.png)

    

19. Reference 결과를 자세히 확인하려면
    - {디렉토리명}_recog_Each.syl을 확인해본다
    - syl파일을 엑셀에 끌어담으면 파일이 열린다

    

>어려울때 참조할 내용들
>
>```
>인식률 평가방법 (개발팀이 주신것)
>1. server.cfg 접속 (w2l-Train-04)
>2. /root/wav2letter/build 들어가서 nohup ./Server -flagsfile 경로위치 예시(DATA/w2l_20200318/base_kor_8k/server.cfg) &
>3. tail -f nohup.out (연결완료 확인)
>4. /root/wav2letter/recipes/korean/test
>      python batch_client.py -i 정제데이터경로 -o 정제데이터경로 -e euc-kr
> 5. result 생성된 디렉토리 이동 /data1/minds/TEST
> 6. 인코딩변경 명령어
> python iconv_file.py -sf utf-8 -cf euc-kr -d ./디렉토리명
>7. 디렉토리명 들어가서
> cd iconv_output
> yes | mv *.txt ../
>yes | mv *.result ../
>txt, result 모두 이동
>8. iconv_output 삭제
>9. cd data1/minds/TEST에서
>./do_evaluation.sh 디렉토리명
>10. Reference 결과 확인
>디렉토리명_recog_each.syl
>
>4번까지 도커안에서하고
>5번부터 밖에서
>```
>
>ps {-ef} | {grep} 어떤 코드가 떠있는지 찾아보는것 
>
>서버 상황 보는것 `netstat`
>
>토큰: 학습할때 lm모델에잇는 글자들을 적어놓은것
>
>Docker
>
>- `docker ps` 는 ls 같은것
>- `docker ps -a`는 죽은거까지 보는것
>- `docker exec -it {이미지 이름} /bin/bash`
>- Docker 주소는 data/**w21**
>- 밖은 data1/minds/w21/**w21** 위의 두 bold채가 같은 주소!
>
>경로는 /data1/minds/w2l_20200318/w2l_20200318/test여기 참조





### :two: TTS

> 6번에서 진행
>
> tts 파라미터 조절은 메일 김혜린매니저님이 보내주신것 참고하기
>
> 진행방법은 아래의 confluence확인하기
>
> `https://pms.maum.ai/confluence/pages/viewpage.action?pageId=12519617&focusedCommentId=15345395`

#### 전처리

- `wav` 직접 들어보고 `txt`와 비교후 txt 수정 (Python아니고 직접해야함)
- 기호는 `?` `!` `,` `.` `''` `""` 만 허용
- 쉼표는 띄어쓰기보다 길게
- nas 서버의 `\\10.122.64.181\DATA-Team\tmp` 경로에 원하는 폴더 안에 저장해준다.

- 6번서버의 `/data1/minds/resources/tts/`에 폴더를 생성

  - ex) aurora     -> target이 aurora 인 경우
  - 그 안에 `22k_wav`폴더, `aurora.txt` 를 넣어준다. (아래그림의 test,train,val은 학습할때 생겨 나는 것 들!)
  - ![image](https://user-images.githubusercontent.com/60081254/95424482-aa709900-097d-11eb-9848-bcbe8ee79c5b.png)

  

#### 학습

1. 6번서버에서 `workon waveglow`

2. `cd /home/minds/maum/resources/tts`

3. `vi make_txt_onefile.py` 명령어 후 수정
- 18번째줄 경로 정하기 (학습할 파일이 있는곳)
- 47번째줄 학습할 폴더이름
   - 48번째줄 새로만들 트레이닝 파일 이름
   - vi나갈때는 esc누르고 `:wq`
   - 저장안하고 나갈때는 esc누르고 `:q!`

4. `python make_txt_onefile.py`실행하면, 잘됐다면

   - /data1/minds/resources/tts/{원하는파일경로: aurora} 에
     - `test.txt`, `train.txt`, `val.txt` 파일 생성되어있다.

5. 우선 타코트론2를 학습시켜본다

   - `cd /home/minds/maum/lib/python/maum/brain/tts/tacotron2/train`
   - `vi hparams.py`
     - 21번째줄에 써있는 포트번호 확인 (현재40001)
     - 위의 포트번호가 사용중인지 확인
       - haparams.py 실행중인것 밖으로 나와서
       - `netstat -nlpt` 실행 후 포트 사용중인가 확인
       - 사용중 아니라면 계속진행
   - 다시 `vi hparams.py`
     - 29번째줄 `training_files='{경로: aurora/aurora_train.txt}'`
     - 30번째줄 `validation_files='{경로: aurora/aurora_val.txt}'`
     - 31, 32번째줄 언어선택
       - 한국어이기때문에 `lang='kor'`
     - 62번째줄 `speaker=['{말하는사람이름: aurora}']`
     - 108번째줄 `batch_size=8`
       - 이건 원하는데로 바꾸기! 
       - 혜림매니저님은 8로 많이하신다
       - 14로하면 한번에 많이씩 데이터가 들어간다
         - 빠르지만 터지는것 주의
       - 4로하면 쪼개서하지만 자주하는것
   - `cd /home/minds/maum/lib/python/maum/brain/tts/tacotron2/train`
   - GPU를 사용하기위해 몇번이 사용중인지 알아본다
     - `watch -n 1 nvidia-smi`
     - 조금기다리면 GPU사용량 뜨는데 맨아래 몇번이 돌아가는지 뜬다
     - 내가 쓰려는게 사용중이 아니라면 계속 진행
     - 사용중이라면 GPU죽인후 진행(이건 조심하자 누가쓰고잇을지 모른다)
   - 나가는 방법은 `Ctrl+c`
     
   - `nohup python -m multiproc -d {사용하려는 GPU번호:0} -d {사용하려는 GPU번호:1} trainerd.py -c {사용하려는모델 여기서는 baseline모델을 사용했다:2019_09_02_fp16_22k_kor_base_2_178000} --warm_start --hparams=distributed_run=True &`
     - 위의 코드 맨마지막 &를 치면 뭐가 막 안뜨고 깔끔한 shell창 유지 가능
     - 위의 코드 너무 지저분하므로 정리된 것은
       - `nohup python -m multiproc -d 0 -d 1 trainerd.py -c 2019_09_02_fp16_22k_kor_base_2_178000 --warm_start --hparams=distributed_run=True &`
     - GPU를 많이쓴다고 무조건 빨라지는건 어니다!
     - `watch -n 1 nvidia-smi` 명령어로 GPU 돌아간느지 확인 한다!

6. tensorboard에 들어가서 확인해볼 수 있다.

   - `cd /home/minds/maum/logs/tts/tacotron2`

   - `ll` 찍어보면 오늘 만들어진 폴더가 있을거다 그안에 들어가자

   - `cd {오늘만들어진폴더이름: 2020_08_28-173821}`

   - `ll` 찍어보면 에러파일확인할수잇다

     - 돌아가다 죽으면 무슨에러엿는지 확인 가능하다

   - 아예 눈으로 보려면 tensorboard 띄워볼 수 있다.

   - 그전에 tensorboard가 이미 사용중인지(떠잇는지)확인해보자

     - `ps -ef | grep tenso`
     - 따로 떠잇는게 없다면 킨다
       - `nohup tensorboard --logdir=. &`

   - tesorboard 주소를 웹창에 친다(크롬 등)

     - tacotron2 텐서보드주소 `{서버주소:182.162.19.6}:6006/#scalars` 

   - 그러면 위의것들이 돌아가는동안(타코2가 돌아가는동안) 해야할 것이 두가지가 있다

     1. 로그를 적는다(사용한 기록)

        - 파일은 공유 드라이브의 Logs의 tmp2.txt 파일에 작성

        - 양식은 다음과 같다

        - ```txt
          aurora 김혜린    #뭘하는건지 누가쓰고잇는건지(본인)
          T2 emb
          @182.162.19.6 GPU 0~1   #0번부터 1번까지 GPU사용하고 있다는것을 기록
          2020_08_28-173821     # 타코트론 전처리는 이폴더야 를 꼭 적어줘야 다음에 이 숫자가 무슨의미인지 알수잇다.
                                  #이것들처럼 아래것들도 알아볼수만 잇게 남기는 목표!!
          T2 Post-emb
          @182.162.19.6 GPU 0~1
          2020_08_28-182049
          
          wg
          @182.162.19.6 GPU 2~3 
          2020_08_28-174429
          
          tenso
          6007 : t2
          6006 : wg
          
          wav files
          @182.162.19.6
          /home/minds/maum/resources/tts/aurora
          ```

     2. 타코가 돌아가는 동안 Waveglow도 돌린다(동시에한다, GPU여러개쓰고 잇으니 가능)

7. Shell로 돌아가서 `cd /home/minds/maum/resources/tts`

8.  `vi config_wg.json`

   - 7번째줄은 체크포인트가 몇씩떨어지게할지정하는것 보통 5000
   - 10번째줄은 남자인지 여자인지 모델 정하는것
     - 남자:
     - 여자: `waveglow_226000_kss_kva`
   - 13번째줄은 경로 적기 예시: `aurora/aurora_train.txt`
   - 23번째줄도 validation파일경로 적어주기: `aurora/aurora_val.txt`
   - 28번째줄의 포트가 다른것이랑 안곂치는지도 확인해본다. (현재40002번 그때그때 다를수 있음)

9. `cd /home/minds/maum/lib/python/maum/brain/tts/waveglow/train`

10. `nohup python distributed.py -d {사용할 GPU:2} -d {사용할 GPU:3} -c config_wg.json &`

   - 위의것 깨끗하게쓰면 `nohup python distributed.py -d 2 -d 3 -c config_wg.json &`

11. `cd /home/minds/maum/logs/tts/waveglow` 에 들어가서 로그확인

    - `ll` 찍어봐서 방금생긴(아마 맨마지막) 파일을 적어준다

    - ```
      aurora 김혜린    
      T2 emb
      @182.162.19.6 GPU 0~1   
      2020_08_28-173821     
      
      T2 Post-emb
      @182.162.19.6 GPU 0~1
      2020_08_28-182049
      
      wg
      @182.162.19.6 GPU 2~3 
      2020_08_28-174429       #여기에 방금 찾은 마지막 파일을 적어준다
      
      tenso
      6007 : t2
      6006 : wg
      
      wav files
      @182.162.19.6
      /home/minds/maum/resources/tts/aurora
      ```

12. `cd 2020_08_28-174429 ` (11번에서 찾앗던 마지막 폴더)

13. `nohup tensorboard --logdir=. --port=6007 &`

    - 이전엔 기본포트엿는데 이번엔 기본못쓰므로(이미쓰고잇으므로) 직접 포트번호 지정
    - 오류주의: 위의 명령어는 꼭 12번의 폴더이동을 하고 해줘야한다

14. waveglow직접확인은 `{서버주소:182.162.19.6}:{포트번호:6007}/#scalars` 

    - `duration` 과 `training.loss`가 잘 나오고있다면 잘 되가는거다!
      - `training.loss` 와 `learing.rate`를 헷갈리지 말자!

15. 또한가지 확인하는 방법은 GPU를 확인해보면된다.

    1. `watch -n 1 nvidia-smi ` 하고 (여기서 1은 1초에한번씩 보여달라는것)
    2. GPU몇번에 뭐가 들어가고있는지 확인해보면 된다.
    3. 만약 GPU가 0%가 되엇다면 (떨어지면) 인풋데이터를 확인해보아야한다
       - 사용할 수 없는 특수문자가 있는지
       - 숫자가 있는지
       - 영어가 있는지
    4. GPU 나가는 방법은 `ctrl+c`

16. 지금까지 한것은 1차학습이었다 이제 2차학습을 시작할것이다 (타코트론2)

17. 2차학습

    1. 서버의(지금은6번에서하니깐 6번서버) `/data1/minds/trained/tts/tacotron2/{타코1차 돌아간결과 생긴폴더:2020_08_28-173821}` 들어가보면 

       - checkpoint_0
       - checkpoint_500이 있을거다
       - 위의 500을 밖으로 뺀다 (로컬)
       - 그후 이름을 바꾼다
         - `checkpoint_500_aurora`

    2. 1차학습돌아가고 있는것을 내린다(끈다)

       1. shell에서`watch -n 1 nvidia-smi `
       2. 돌아가고있는 GPU의 `PID`를 확인
       3.  `kill -9 {PID:13036} {PID:13037}`
       4. `watch -n 1 nvidia-smi ` 다시치고 들어가면 내려간것 확인

    3. `cd /home/minds/maum/lib/python/maum/brain/tts/tacotron2/train`

    4. 아까 1번에서 옮겨서 이름바꾼폴더(`checkpoint_500_aurora`)를 `/data1/minds/trained/tts/tacotron2` 에 다시 옮겨놓는다 ( 아까것을 하나만빼서 이름바꿔서 다시 이동시켜넣는 과정이라 생각하면된다.)

    5. `vi hparams.py`

       - 만약 이 2차학습을 주말에 띄워놓을것이면 이 과정을 진행하면된다.
       - 주말동안 500단위로 checkpoint가 생기면 파일이 너무많이생겨서 용량초과로 떨어질 수 있다.
       - 그래서 단위를 넓혀놓고 주말에 돌아가게 하는 작업
       - 15번째줄 2000으로 수정
       - 29,30번째줄 수정

    6. `nohup python -m multiproc -d {쓸 GPU 번호:0} -d {쓸 GPU 번호:1} trainerd.py -c {쓸파일:checkpoint_500_aurora} --hparams=distributed_run=True &`

       - 깨끗하게쓰면
       - `nohup python -m multiproc -d 0 -d 1 trainerd.py -c checkpoint_500_aurora --hparams=distributed_run=True &`

    7. `cd /home/minds/maum/logs/tts/tacotron2`

    8. `ll` 확인하면 방금생겨난 맨마지막폴더를 로그에 적어 놓자

       - ```
         aurora 김혜린    
         T2 emb
         @182.162.19.6 GPU 0~1   
         2020_08_28-173821     
         
         T2 Post-emb
         @182.162.19.6 GPU 0~1
         2020_08_28-182049    # 여기에 두번째 타코트론학습 폴더를 적어준다.
         
         wg
         @182.162.19.6 GPU 2~3 
         2020_08_28-174429       
         
         tenso
         6007 : t2
         6006 : wg
         
         wav files
         @182.162.19.6
         /home/minds/maum/resources/tts/aurora
         ```

    9. tesorboard 들어가서 잘 되고있는지 확인하고 주말동안 결과를 기다린다.

       1. `cd {아까마지막 폴더}`
       2. `ps -ef | grep tenso`
          1. 이전에 1차학습때 켜져잇던 텐서보드를 지운다
             - `kill {1번명령어쳣을때 나오는 맨 앞의숫자 (아마이걸PID라고하는것 같다):13766}`
          2. `nohup tensorboard --logdir=. &`  
       - nohup으로 하는 이유는 컴퓨터 꺼도 알아서 돌아가게 하는 명령어이다.

       - `182.162.19.6:6006/#scalars`

18. **The End!**



#### 결과 듣기

> TTS는 인식률 테스트가 없고, 직접 귀로 들어봐서 가장 좋은 소리를 찾아야 한다.

1. 6번서버를 실행한다 (shell, Filezilla 둘다 내가 학습때 사용했던 서버를 키면된다)

2. `workon waveglow`

3. `cd /home/minds/maum/bin` 

4. Filezilla는 

   - `/data1/minds/trained/tts/tacotron2`
   - `/data1/minds/trained/tts/waveglow` 이 두군데에서 좋은 파일을 찾아 줄 준비를 한다.

5. tensorboard를 킨다

   - Tacotron2는 `http://182.162.19.6:6006/#images` 
     - 여기서 alignment 가 가장 일자인것이 잘 나온것이다
     - 가장 잘 나온것의 파일 명을 기억한다
     - Filezilla에서 그 파일의 파일명 뒤에 `_aurora` 처럼 화자를 달아준다
       - `checkpoint_6000` -> `checkpoint_6000_aurora`
   - waveglow는 `http://182.162.19.6:6007/`
     - 위의 것은 waveglow가 만든음성
     - 아래 것은 진짜음성 (맞춰야하는 음성)
     - 위의 두개가 가장 비슷한 것의 checkpoint를 기억한다
     - Filezilla에서 그 파일의 파일명 뒤에 `_aurora` 처럼 화자를 달아준다
       - `waveglow_540000` -> `waveglow_540000_aurora` 

6. 이제 다시 shell로 가서(혹시새로하는거면 `workon waveglow`)

   - `brain-tts dev`

   - `brain-tts-rest dev`

   - ` python brain-tts-tacotron2 -m /data1/minds/trained/tts/tacotron2/2020_08_28-182049/checkpoint_6000_aurora -d 0 -s 1500 -t 0.01 -p 30101 &`

     - 위의 코드는 python brain-tts-tacotron2 -m {장소/가장좋은 타코트론} 옵션값 & 로 생각하면 된다 

   - `python brain-tts-waveglow -m /data1/minds/trained/tts/waveglow/2020_08_28-174429/waveglow_540000_aurora -s 0.666 -ds 0.01 -d 1 -p 35101 &`

     - 위의 코드는 python brain-tts-tacotron2 -m {장소/가장좋은 웨이브글로우} 옵션값 & 로 생각하면 된다 

   - 위의 옵션값들은 다음과 같다

     - | 모델   | tacotron2   |            | waveglow               |            |
       | ------ | ----------- | ---------- | ---------------------- | ---------- |
       | 옵션값 | s: 잡음조절 | t          | s: 안정성              | ds: 기계음 |
       | 높으면 | 안녕하세요~ | 0.01(고정) | 울린다(동굴소리)       | 금속소리   |
       | 낮으면 | 안녕        | 0.01(고정) | 깔끔하지만 안정성 감소 | 먹먹함     |
       
     - 상세설명
     
       - tacotron2
     
         t가 낮은 경우 - 말이 다 나오지 않음(문장을 다 만들지 못함)
     
         t가 높은 경우 - 말이 다 나오고 나서도 음성이 끝나지 않고 이상한 말이 나옴
     
         s가 낮은 경우 - 음성의 길이가 s*256 / 22050초(-s 1600 기준 약 18초)이면서 말이 다 나오지 않음
     
         s가 높은 경우 - 음성의 길이가 s*256 / 22050초일 때, GPU의 RAM이 
     
       - waveglow
     
         s가 낮은 경우 - 특정 주파수의 소리가 생김, 전반적으로 먹먹한 느낌이 생기며, 음성의 안정성이 낮아지나(목소리가 떨리는 등), 울리는 소리가 감쇄됨
     
         s가 높은 경우 - 전반적으로 음성의 안정성은 높아지고 선명해지나, 울리는 소리가 생김
     
         ds가 낮은 경우 - 소리는 명료하나, 특정 주파수의 소리와 지저분한 소리(금속음, 풍절음 등)가 남아 있음
     
         ds가 높은 경우 - 특정 주파수의 소리와 지저분한 소리(금속음, 풍절음 등)가 지워지지만, 소리가 약간 먹먹해짐
     
     - 기본값
     
       - taco2: -t 0.1, -s 1600
       - wg: -s 0.666 -ds 0.01

7. `http://182.162.19.6:9998/tts-rest/` 를 들어간다 (고른 taco와 wav 를 섞어서 직접 들어보는 것)

   1. 원하는 스크립트를 친다

      - 하지만 권장하는 스크립트 있다.
      - 공유드라이브 - Working - KL 의 **TTS결과값확인스크립트** 의 문장들을 사용하면 더욱 좋다
2. 아래의 `Go` 나 `Preprocessing` 을 누르고 기다린다
   
   - 긴 스크립트일수록 오래걸린다
   3. 나오는 소리를 들어보고 소리가 괜찬으면 파일을 저장

      - 파일 명

      - taco2 체크포인트, 옵션 값
   - waveglow 체크포인트, 옵션 값
      - 위의 3개를 저장해두면 다른 값들과 비교하기 좋다
   4. 소리가 마음에 들지않으면 taco2와 waveglow 파일을 바꿔가며, 옵션값을 바꿔가며 최적의 소리를 찾는다
      1. 이때 `ps -ef | grep brain` 을치면 방금전에 올린 명령어가 잇을거다
   2. 여기서 PID확인한 후에 kill 해주고 새로띄워줘야한다 
   
8. **The End**!



#### API 넘기기

> 위의 모들 과정이 끝나면 어떠한 서버에 띄워서 듣고 API정보를 연동시키고, 연동된 API 정보를 전달하는 과정이 필요함.

1. Shell 6번서버 켜기

   1. `workon waveglow`

   2. `cd build`

   3. `cd waveglow`

   4. `cd remake`

   5. 이곳에 가장 좋은 결과였던 waveglow파일을 복사한다.

      - 이것은 cp명령어를 사용하면 편하다
      - `cp {옮길파일위치/이름} {옮겨질파일위치/이름}`
      - 예시로 `cp /data1/minds/trained/tts/waveglow/2020_09_15-121139/waveglow_250000_dubu /home/minds/build/waveglow/remake/waveglow_250000_dubu`
      - 옮겨질 위치에서 이름 바꾸면 바뀐 이름으로 복사된다.

   6. 다옮겨진 후에 `./a.sh` 실행

      - 완료 되었다면 해당 파일 뒤에 `_re` 가 붙은 파일이 생긴다
      - 예시로 `checkpoint_240000_dubu` 였으면 `checkpoint_240000_dubu_re` 가 생길 거다.
      - taco말고 waveglow 파일만 _re로 붙이는거 맞는거니 당황 ㄴㄴ

   7. `_re` 파일이 생성 되었다면 `https://docs.google.com/spreadsheets/d/19fMDRfE4o79EPsw3-ASDSqqDzL2twaxK8vfgdm7060Q/edit#gid=0` 이곳에 들어가서 나의 가장 좋았던 taco2 와 waveglow의 `파일명`, `파라미터`모두 적어놓는다

      - 이따 waveglow는 `_re` 파일임을 잊지말자

   8. 그럼 이제 해당 taco2, waveglow 파일들을 101번서버에옮겨놓는다.

      - `/home/mindslab/model` 이 위치에 타코는 타코에 웨글은 웨글에 옮겨놓으면 된다.

   9. 다 적었으면 적은 부분을 캡쳐해서 tts-ten 방의 `오세진 대표`님께 슬렉드린다.

      - 양식

      - ```
        안녕하세요. 오세진 대표님,
        스트리머 연두부 모델 추가 부탁드립니다.
        {캡쳐사진}
        ```
        
      - ![image](https://user-images.githubusercontent.com/60081254/95424536-be1bff80-097d-11eb-8e30-821740b15200.png)

   10. 오세진 대표님께서 포트번호를 주시면 4가지항목을 `유종호 매니저`님꼐 드린다 

       - 드릴 항목과 예시
         - 모델있는 서버  `114.108.173.101 서버`
         - 포트번호   `30802`
         - 모델명  `dubu`
         - 화자 `0`번
           - 여기서 화자는 몇명이 말햇는지를 의미
           - 만약 3명이 발화한 것이면 0,1,2이므로 `2`를 적으면 된다.
       - ![image](https://user-images.githubusercontent.com/60081254/95424592-d12ecf80-097d-11eb-995a-cad91a5e57cd.png)

       - 저기서 `dubu 모델을, ejn, ju~~` 여기는 dubu님의 회사이름이 ejn이기때문에 한 것. 모르겠으면 혜린매니저님께 문의

       

   11. 해당 api에 연동이되면

       - 직접인텔리제이로 DB에 들어가서 두부님만 사용할 수 있는 아이디 페스워드만들어야한다.
       - 만들어서 샌드박스에 ID PS를 전달해준다 
         - (메일로 : 안녕하세요 마인즈랩~ ~ ~이규민입니다. 어찌구저찌구 불안정한 부분은 추후 개선 가능하오니 ~ ~ 주시기 바랍니다. 감사합니다.)

   12. 마지막 팁!

       - 특정 날짜까지 메일을 전달할거면 적어도 하루전까지는 모든걸 끝내놔야한다.
       - 만약 이모든 과정의 어떠한 담장자가 휴가인 경우나 갑자기 무슨 기능이 안되면 계약 날짜를 맞추지 못한것이니 미리미리 해놓자!




#### API 연동 확인

> Postman을 사용한다.

- postman 사용법은 이규민 작업공간에서 `Postman 사용가이드`를 참고하시오

- ```
  "apiId" : "juho-minds-api",
  "apiKey" : "62fd4f9c135644f3935c4beb0f933018",
  ```

- 위에꺼에 스프레드시트에 써논 Voice 이름만 바꿔서 사용하자
- **대소문자 주의!**



**TTS 진짜끝!!**



### :three: 기타 정보

#### TTS, STT 제작 비용

TTS 는 따로 개발할 것이 없으므로 계약시작부터 매달 돈을 내면된다

- Shared 서버: 매달 27만원
- dedicated 서버: 매달 63만원

- 대신 녹음실 비, 성우 섭외비는 직접 내셔야 한다.

STT는  따로 개발이 필요하므로 개발 비를 내야한다

- 개발과정에서는 매달 500만원(3~6개월)

- 유지보수에서는 금액 새로 측정해야한다.

  - revenue share
  - api 사용량에 따른 재 논의

  

#### TTS, STT revenue share

revenue share에 계약서들은 `\AICS Dept\Muse\2. Documentation\Streamer` 여기에 있다!

- 개인이 계약할때는 `귀사명` 에 해당하는것을 다 지우면 된다.

- revenue share 비율은 다음과 같다

- | 상황                  | Default<br />(샌드박스는여기) | 소개없이 개인적으로<br />바로 연락온 경우 | 소개는 받았지만 <br />소속사가 없는경우 |
  | --------------------- | ----------------------------- | ----------------------------------------- | --------------------------------------- |
  | TTS 요금              | A                             | A                                         | A                                       |
  | 시스템비용<br />(EJN) | A * 17.5%                     | A * 15                                    | A * 20                                  |
  | 귀사명(소속사)        | A * 5%                        | A * 5                                     | A * 0                                   |
  | 스트리머성명          | A * 50%                       | A * 50                                    | A * 50                                  |
  | 엔진사비용(마인즈랩)  | A * 27.5%                     | A * 30                                    | A * 30                                  |

  



#### TTS 녹음 갈때 참고

> 레벨나인 스튜디오
>
> 01045577038

- 문의 시 `김혜린 매니저와 함께일합니다` 라고 소개 반드시 할것

  - 나중에 세금계산서를 한번에 받기 위함
- 스튜디오는 A,B룸이 있다 (우리는C룸은 사용하지 않음)
  - A룸: 스트리머 분들 오실 때 사용
  - B룸: 성우분들 녹음하실 때 사용
- 소속사가 있는경우 담당하는 팀장님이나 매니저가 나올거다
- 소속사가 없으면 개인이 나올거다
- **녹음날 계약서를 다 작성해서 가져가**야 등기로 왓다갓다 안하고 편하다
  - 이건 3자 계약을해야해서 왓다갓다 많이해야하니깐 이때 하는게 편하다
  - 계약서 가져가는 방법
    - 프린트한다
    - `AICS Dept\Muse\1. Admin\Invoice` 에 있는 **invoice 파일을 표지로 동봉**한다 !
    - 스테이플러찍지말고 집게 클립으로 묶는다
    - 투명화일에 넣는다
    - 등기봉투에 넣는다
    - 녹음날 준다
- 만약 계약서를 서로 등기로 왓다갔다해야하면 아래를 참고하자
  1. 만약 3자계약이라면 계약서를 3부를 출력한다
  2. 좌측부터 갑을병 3부를 놓고 각 문서사이에 모든페이지에 사이간인을 한다
  3. 모든페이지마다 반절씩 접어서 모든페이지 사이에 사이간인을 한다
  4. 서명한는곳(보통계약서 마지막)에는 `스트리머 녹음일`을 기준으로 서명일에 날짜를 적는다
  5. 도장 다찍은 파일은 클립(납짝한거) 을 각각찍는다
  6. 투명화일에 넣는다
  7. 보내는곳 주소를 프린트한다(크게)
  8. 짤라서 종이봉투(마인즈랩봉투)에 받는분에 붙인다
  9. 내용물 넣어서 동봉한다
  10. 심나리 매니저님(재무팀)께 등기보내려고 법인카드 부탁드린다
  11. 지하1층 오른쪽가면 우체국 있다 거기가서 보낸다
  12. **영수증 꼭 가져온다**
  13. 인사팀 뒤쪽 법카 폴더있다 그거 꺼내서 영수증 넣어놓고 법인카드 사용대장 작성한다
      - 이때프로젝트코드알아야하므로 알아간다
      - 카드는 아직 반납하지말자 카드 맨 뒷번호 써야한다
  14. 다하고 심나리매니저님께 반납하면 끝이다 수고했다.



## ------------------------------------

## * 유용한 IT 지식들

> 당신이 IT업계에서 살아남고 싶다면 알아둬서 나쁠 것 없는 것들입니다. (사실 내가 몰라서 만듬)
>
> `data` `bigdata` `docker` `ai` `linux` `rpc` `DL` `ML`

### :one: Docker

> 도커환경에서의 TTS 학습을 연습이므로 꾸준히 업뎃될 예정입니다.. (2020 10.05~ 현재 진행 중)
>
> 1. https://pms.maum.ai/confluence/pages/viewpage.action?pageId=25695639 의 TTS in docker를 참고하여 만들어진 문서 입니다. (윤서영 매니저님 컨플)
> 2. 도커에대한 자세한 용어정리는 https://subicura.com/2017/01/19/docker-guide-for-beginners-1.html 여기가 아주 좋다! (`image`, `container` 등...)
> 3. 컨플루엔스 - 실무교육 -cli기초 - linux docker 공부하기
>
> ```txt
> 현재 6, 9번서버에 TTS 사용을 위한 Docker 환경 구축 계획입니다. 환경구축이 완료되면  6번 서버의 /home/minds/maum/trained/tts/waveglow 의10.05일자 waveglow 파일이 있다 활용하여 도커환경에서 돌리기 연습을 해야합니다.
> ```
>
> 

기본적으로 TTS 엔진은 아래 사진과 같은 형태로 돌아가게 됩니다.

![image](https://user-images.githubusercontent.com/60081254/95424614-dbe96480-097d-11eb-9963-cb87187f23c3.png)

#### Docker 기본 환경 SET

> 윤서영 매니저님 컨플: https://pms.maum.ai/confluence/pages/viewpage.action?pageId=25695657
>
> Docker 개념정리: https://cultivo-hy.github.io/docker/image/usage/2019/03/14/Docker%EC%A0%95%EB%A6%AC/#sudo-%EC%97%86%EC%9D%B4-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0
>
>
> 이제는 taco 가 아니라 https://pms.maum.ai/confluence/display/audio/TTS 에서 알려주는 DCA로 한다.

- docker 권한주기
  - `sudo usermod -aG docker $USER`   현재 접속중인 사용자에게 권한 주기 (이거쓰삼)
  - `sudo usermod -aG docker your-user`  ypur-user 사용자에게 권한주기 (이거사용 할일잇을까?)

- docker 켜기
  - `sudo systemctl start docker`

- docker image 받기
  - tacotron2:  `docker pull docker.maum.ai:443/brain/tacotron2:1.2.7-server`
  - waveglow: `docker pull docker.maum.ai:443/brain/waveglow:1.2.7-server`
  - grpc: `docker pull docker.maum.ai:443/brain/tts:1.2.7-server`
- 다운받은 도커 이미지를 보는 명령어
  - `docker images`
- 도커 이미지를 삭제하는 명령어
  - `docker rmi {이미지 ID}`

#### Docker TTS 학습

- tacotron2 컨테이너 생성
  - `docker run -itd --ipc host --gpus '"device=**0,1**"' -v **/[DATA1:/DATA1](http://data1/DATA1)** -e LC_ALL=C.UTF-8 --name **taco_train** docker.maum.ai:443/brain/tacotron2:1.2.7`
  - docker run {옵션} {이미지 이름} {실행할 파일} 형식
- waveglow 컨테이너 생성
  - `docker run -itd --ipc host --gpus '"device=**0,1**"' -v **/[DATA1:/DATA1](http://data1/DATA1)** -e LC_ALL=C.UTF-8 --name **wg_train** docker.maum.ai:443/brain/waveglow:1.2.7`

- 생성한 컨테이너 목록 출력```````````````````````````````````````````

  -  `docker ps -a`

- 기타 기본적인 정보 밑 명령어

  - docker 환경에서 뭔가 안되면 `sudo` 명령어를 맨앞에 붙여서 해보자 sudo = super do 로 관리자 권한 실행이다.

  - docker 의 컨테이너를 지우기 위해서는 컨테이너를 중지 시킨 후 삭제할 수 있다.

    - `docker stop hello`  :hello 라는 컨테이너를 중지
- `docker rm hello` :hello 라는 중지된 컨테이너를 삭제
    - `docker inspect {ID 또는 name}`  :image 또는 container의 세부 정보 출력
- `docker start hello` : hello 라는 중지된 컨테이너를 켜는것

#### 



### :two: Linux

> 당신이 리눅스 환경이 익숙치 않다면 아래 명령어만 익혀도 전혀 문제가 없을 것 입니다. (2020.10.08 작성 미완료)

- ls

  > 현재 위치의 파일 목록을 조회

- cd

  > 

- touch

  > 

- mkdir

  > 

- cp

  > 

- mv

  > 

- rm

  > 

- cat

  > 

- redirection

  > 

- alias

  > 



### :three: RPC

- 어떠한 서버에서 API를 받아와서 사용하고자 한다.
  - 우리는 API Document의 사용법만 확인하여 순쉽게 구현이 가능하다
- 하지만 **현실은** `네트워크`, `서버`, `클라이언트` 등 각종 문제가 발생할 수 있다.
- 그 모든것을 개발자가 직접 다 컨트롤하려면 힘들기 때문에 등장한것
  - **RPC**
  - 즉, RPC는 `Server`에 있는 프로그램 정보를 알고있는 `IDL(Interface Definition Language)`를 활용해서 개발자는 네트워크, 통신 등과 관련된 작업은 신경 쓰지 않아도 되고, **원격지에 위치한 프로그램을 로컬에 있는 프로그램 처럼 사용** 할 수 있습니다.
- gRPC: 구글에서 개발한 RPC
- 결론: 좋은거다 짱짱맨

### :four: REST

- 웹에서의 일종의 **스타일**을 의미
  - `Http 1.1`을 사용하며
  - url을 자원(resource)로 표현하고
    - url에 동사없이 명사로만 구성을 해야 한다.
      - ex) http://www.o.com/user/summy/profile/address 이런식
  - 처리결과를 Status Code로 사용한다
    - 기존에는 http의 처리 결과를 header의 Status Code는 200으로, 처리결과는 body에 작성
    - 하지만 RESP에서는 처리 결과를 header의 Status Code를 활용한다.
- 이러한 REST가 제안하는 스타일에 맞는다면
  - **RESTful 하다** 라고 말합니다.

## ------------------------------------

## *사업 현황

> 사업 현황은 업뎃안된지 오래댔으니 **참고**만 하시길 바랍니다...

### STT

#### edulab

> CNN-STT
>
> 아이들이 말하는것 -> Text -> 평가

- `8/24` 데이터명 통일 전처리 진행

- `C:\Users\mindslab\Desktop\업무\edulab\통합\proprecessing.py`

- `8/25` 기호 삭제 전처리 진행

  - `C:\Users\mindslab\Desktop\업무\edulab\통합\기호삭제.py`

- `8/26` STT 인식률 결과 보고서 전송

  - `‪C:\Users\mindslab\Desktop\업무\edulab\STT 인식률 결과 보고서.pdf`
  - good data / bad data 예시 전송

- `8/27` 

  -  docker 들어와서
  -  서버 켜서
  -  cd로 위치들어간다 (4)
  -  파이썬파일켠다 (4)

- `8/28`

  - STT 모델 인식률 테스트

    > 이전에했던 모델이 아닌 `server_kor_hoe.cfg`, `회의록모델`, `HC_CNN` 파일로 인식률테스트 해보기

    - shell켜서
    - 7번 서버 on
      - id: `minds` pw: `msl1234!`
    - ps {-ef} | {grep} 어떤 코드가 떠있는지 찾아보는것 
      - ps 뒤에것은 옵션값
    - 서버 죽일때는 kill -9 {15376} {25374}
    - cfg가 컨피그 파일이어서 나머지것 미리만들기
      - `HC_CNN_IB`
      - `meetinglog`
    - `Token`: 학습할때 lm모델에잇는 글자들을 적어놓은것
    - --w2l 127.0.0.1:14001

- `8/31`

  - 

#### 삼성영어

> CNN-STT 에서 DNN-STT로 업그레이드 예정
>
> 아이들이 말하는것 -> Text -> 평가

- `8/25` 서버 리부팅 문제 발생 -> 해결
  - ![image](https://user-images.githubusercontent.com/60081254/95424675-f4597f00-097d-11eb-925f-145710402016.png)

##### 서버 재부팅

> 삼성영어에서 서버를 재부팅해도 우리의 STT엔진이 함께 켜지지 않는경우에는 아래와 같은 방법을 통해 직접 켜줘야 한다.

삼성영어 서버에 대한 정보는 다음과 같다

- ![image](https://user-images.githubusercontent.com/60081254/95424717-076c4f00-097e-11eb-95bf-b9f2e4c392f7.png)

1. shell을 켠다.
   - ㅇㄹㅇㄹ
2. `sudo systemctl start docker`



### TTS

#### 비상edu

> TTS: 영어교육

- `8/25` 서버 사용 현황 보고서 전송
  - `C:\Users\mindslab\Desktop\업무\비상edu\서버 사용 현황 보고서.pdf`
  - Shared -> Dedicated Server 2개 이용 권장

#### 샌드박스

> 스트리머 Voice pont 제작

- `8/27` 스트리머 인지도 조사 
- `케인` 대비 `슈블` `레비` `막이마기` `박_수현` `제이킴` 인지도 조사


#### 아이오로라

> TTS : 도네이션 Voice pont 만들기

- `8/26` Input 데이터 전처리 작업 완료
  - wav에 맞춰 txt파일 수정
  - `,` 와 ` _(띄어쓰기)` 수정
  - 기호 삭제 (!?,. '' "" 제외)
  - 녹음 안된 부분/잘못된 부분 수정/삭제

#### 연두부

> TTS : 도네이션 Voice pont 만들기

- ~~`~9/2 까지` 데이터 전처리 하기~~
  - 22k_hz, 16비트, mono 형식으로 진행

- `~9/9 까지` 아이오로라 TTS 학습 보고 직접해보기 

#### RedButton

> TTS: 보드게임 설명을 테블릿 음성으로 전환

#### Touch

> 니코니코니~ Voice pont 제작

- Baseline data 생성 (현재 진행중)



### 기타

#### LG U+

> 6가지 프로젝트 의뢰

- 제안서 작성 (완료)



#### TTS Toll 개발 사업

- https://ttsbuilder.maum.ai/

## -----------------------------------

## * 업무환경 세팅

> 처음에 회사에오면 당황스럽겠지만 서버?계정? 모르는게 많을때 큰 힘이 되어줄 것입니다.

### maum.ai 계정(구글)

- ID: `lkm@mindslab.ai`
- PW: `941219asd!`

### Server

- NAS 서버

  > 윈도우키 + R 눌러서 주소 입력후 open

  - 주소: `\\10.122.64.181` 
  - ID: `datateam` PW: `data2019!@#`

- 6번

  > Filezilla를 통해 open
  >
  > new site누른후 프로토콜 sftp 로 변경 후 아래의 주소들 진행
  >
  > 6,7,9 동일

  - 주소: 182.162.19.6
  - ID: `minds` PW: `msl1234!`

- 7번
  
  - 주소: 182.162.19.7
- ID: `minds` PW: `msl1234!`
  
- 9번
  
  - 주소: 182.162.19.9
- ID: `minds` PW: `msl1234!`
  
- ~~12번(?)~~
  
  - ~~주소: 182.162.19.12~~
  - ~~ID: `minds` PW: `msl1234!`~~

- 101번
  
  - 호스트: 114.108.173.101
  - ID: `mindslab` PW:`ml142314`

### VPN

> Maum이 아닌 다른 와이파이를 사용하는 경우 항상 VPN이 필요하다

- Hillstone Secure Connect 프로그램 연결
- Server: `125.132.250.203`
- Port: `4433`
- Username: `lkm`
- PW: `lkm1234!`



### 공유드라이브

- 날짜+간단한내용 으로 폴더만들고
- 내용이되는 어떤 파일은만들때 {날짜}{간단한내용}_{v1}버전을 써준다! 
  - 수정받고 v2 이렇게 올린다.
- 프린트하는것은 vf 프린트안하고 보내는것은 vs를쓴다
- pptx나 excel파일은 pdf로 바꿔서 꼭 올려준다(원본도포함)
- 엑셀의경우영역드레그 페이지레이아웃 인쇄영역-인쇄영역설정
  미리보기는 보기-페이지나누기 미리보기



### 프린트

- 프린터는 인프라팀에 문의해서 연결하도록한다
- 엑셀을 프린트할때 
  - sheet가 여러개면 각 페이지마다 단면or양면을 따로 지정해준 후 
  - 한번에 인쇄하면 아마 하고있는 고민이 풀릴 것이다.



### KBS TTS TOOL

> 함부로 사용하지마라 진심이다

https://kbs-tool.maum.ai/?#/login



### 에듀랩

> 함부로 사용하지마라 진심이다

- https://ai.total-system.co.kr:8080/uapi/sample.html 