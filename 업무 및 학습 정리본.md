# 마인즈랩 적응기

> 업데이트 일자: 2021.03.23



## * STT TTS 정보

> 이 문서의 하이라이트인 STT 와 TTS 전처리,학습,아웃풋 통합 정리본 입니다. 
>
> 이문서와 함께라면 따듯한 마인즈랩 생활이 될 것을 보장합니다.
>
> - TTS STT 공부
>
>   - TTS (컨플루엔스 실무교육 공부하기)
>
>     - `https://pms.maum.ai/`
>
>     - `https://startagainbornagain.tistory.com/28?category=720149`
>
>     - RNN LSTM `https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/`
>
> - Docker 공부해보기
>
>   > 컨플루엔스 - 실무교육 -cli기초 - linux docker 공부하기
>
> - 서버기초교육 3개 다보기 

### :one: STT

> 7번에서진행하세요

#### 전처리

- `Python`을 사용하여 전처리 진행
- 데이터명 통일 전처리 진행
- 기호 삭제 전처리 진행



#### 학습

~~아직 정확하게 해보지 않아서 완벽할 때 업뎃 예정~~



#### 인식률테스트

**아래를 순서대로 진행**

1. 7번서버에서 진행(shell 7번서버 켜기)

2. 수도 안으로 들어온다 
   - `sudo su`
   - id: `minds` pw: `msl1234!`

3. docker의 상태를 확인한다
   - `docker ps`
   - 죽은것까지 보려면 `docker ps -a`
   
4. docker로 들어간다
   - `docker exec -it {도커이름, 예시:w2l-Train-04} /bin/bash`
   - 잘들어왔는지 확인
     - `ll`
   
5. 폴더 이동 
   - `cd DATA`
   - `cd w21_20200318`
   - `cd test`
   - `ll` 찍어보기
   
6. 서버환경 만들기
   - `cd ~/wav2letter/build/`
   - `ll` 찍어보면 Server가 있다.
   - `nohup ./Server -flagfile /DATA/w2l_20200318/test/{원하는 파일: server_kor_hoe.cfg} --port {원하는 포트번호: 12345}`
   - 이때 위의명령어를 치기전에 새로운 shell창을 열어서(서버동일) 포트가 사용중인지 찾아본다
   
7. 새로운창에서(도커밖에서)
   - `sudo su`
   - 서버가 뭐가 켜있는지 확인
     - `ps -ef | grep Server`
     - 이때 켜져잇는게 있다면(쓰려는데 켜져잇다면)
       - kill -9 {켜져잇는 포트의 맨앞에 있는숫자 예시: 17459}
   
8. 다시 docker 창으로 돌아와서 명령어 실행
   - 포트연결하기
     - `nohup ./Server -flagfile /DATA/w2l_20200318/test/{원하는 파일: server_kor_hoe.cfg} --port {원하는 포트번호: 12345} --logtostderr=1 &`
   
9. `ll` 찍어보고

10. batch_client.py 파이썬 파일실행
    - `python batch_client.py -i {정제데이터 있는 경로: /DATA/w2l_20200318/test/testdata_edulab2} -o {정제데이터 아웃풋 생기는 경로: /DATA/w2l_20200318/test/edulab_hoe} -e euc-kr`
      - 위의 명령어 실행하다 오류생겻엇으니 파일경로같은거 잘 확인하기
    
11. 위의 결과물이 생성되었다면 result생성된 디렉토리로 이동(여기서부턴 도커 밖에서 한다)
    
    - `/data1/minds/TEST/` 어딘가에 생겻을걸 (아마)
    
12. 인코딩을 변경해준다
    
    - `python iconv_file.py -sf utf-8 -cf euc-kr -d ./{디렉토리명: 11번에서의 디렉토리를 의미}`
    
13. 디렉토리명에 들어간 후 
    - `cd iconv_output`
    - `file *.txt` 명령어를 통해 txt파일들이 잘 인코딩되었는지 확인
    - `file *.result` 명령어를 통해 result 파일들이 잘 인코딩되었는지 확인 
    
14. txt, result 파일이 다 인코딩 완벽하다면 한단계바깥(원본이있는)에 인코딩된 파일들로 덮어씌워준다!
    - `mv *.txt ../`
    - `mv *.result ../`
    
15. iconv_output 폴더 삭제

16. `cd data1/minds/TEST`

17. `.do_evaluation.sh {13~15의 디렉토리명}`

18. 잘됐다면 다음의 창이 나온다

    - ![image](https://user-images.githubusercontent.com/60081254/95424443-99278c80-097d-11eb-8c1c-53370af7d823.png)

    

19. Reference 결과를 자세히 확인하려면
    - {디렉토리명}_recog_Each.syl을 확인해본다
    - syl파일을 엑셀에 끌어담으면 파일이 열린다

    

>어려울때 참조할 내용들
>
>```
>인식률 평가방법 (개발팀이 주신것)
>1. server.cfg 접속 (w2l-Train-04)
>2. /root/wav2letter/build 들어가서 nohup ./Server -flagsfile 경로위치 예시(DATA/w2l_20200318/base_kor_8k/server.cfg) &
>3. tail -f nohup.out (연결완료 확인)
>4. /root/wav2letter/recipes/korean/test
>      python batch_client.py -i 정제데이터경로 -o 정제데이터경로 -e euc-kr
> 5. result 생성된 디렉토리 이동 /data1/minds/TEST
> 6. 인코딩변경 명령어
> python iconv_file.py -sf utf-8 -cf euc-kr -d ./디렉토리명
>7. 디렉토리명 들어가서
> cd iconv_output
> yes | mv *.txt ../
>yes | mv *.result ../
>txt, result 모두 이동
>8. iconv_output 삭제
>9. cd data1/minds/TEST에서
>./do_evaluation.sh 디렉토리명
>10. Reference 결과 확인
>디렉토리명_recog_each.syl
>
>4번까지 도커안에서하고
>5번부터 밖에서
>```
>
>ps {-ef} | {grep} 어떤 코드가 떠있는지 찾아보는것 
>
>서버 상황 보는것 `netstat`
>
>토큰: 학습할때 lm모델에잇는 글자들을 적어놓은것
>
>Docker
>
>- `docker ps` 는 ls 같은것
>- `docker ps -a`는 죽은거까지 보는것
>- `docker exec -it {이미지 이름} /bin/bash`
>- Docker 주소는 data/**w21**
>- 밖은 data1/minds/w21/**w21** 위의 두 bold채가 같은 주소!
>
>경로는 /data1/minds/w2l_20200318/w2l_20200318/test여기 참조





### :two: TTS

> 6번에서 진행
>
> tts 파라미터 조절은 메일 김혜린매니저님이 보내주신것 참고하기
>
> 진행방법은 아래의 confluence확인하기
>
> `https://pms.maum.ai/confluence/pages/viewpage.action?pageId=12519617&focusedCommentId=15345395`

#### 전처리

- `wav` 직접 들어보고 `txt`와 비교후 txt 수정 (Python아니고 직접해야함)
- 기호는 `?` `!` `,` `.` `''` `""` 만 허용
- 쉼표는 띄어쓰기보다 길게
- nas 서버의 `\\10.122.64.181\DATA-Team\tmp` 경로에 원하는 폴더 안에 저장해준다.

- 6번서버의 `/data1/minds/resources/tts/`에 폴더를 생성

  - ex) aurora     -> target이 aurora 인 경우
  - 그 안에 `22k_wav`폴더, `aurora.txt` 를 넣어준다. (아래그림의 test,train,val은 학습할때 생겨 나는 것 들!)
  - ![image](https://user-images.githubusercontent.com/60081254/95424482-aa709900-097d-11eb-9848-bcbe8ee79c5b.png)

  

#### 학습

1. 6번서버에서 `workon waveglow`

2. `cd /home/minds/maum/resources/tts`

3. `vi make_txt_onefile.py` 명령어 후 수정
- 18번째줄 경로 정하기 (학습할 파일이 있는곳)
- 47번째줄 학습할 폴더이름
   - 48번째줄 새로만들 트레이닝 파일 이름
   - vi나갈때는 esc누르고 `:wq`
   - 저장안하고 나갈때는 esc누르고 `:q!`

4. `python make_txt_onefile.py`실행하면, 잘됐다면

   - /data1/minds/resources/tts/{원하는파일경로: aurora} 에
     - `test.txt`, `train.txt`, `val.txt` 파일 생성되어있다.

5. 우선 타코트론2를 학습시켜본다

   - `cd /home/minds/maum/lib/python/maum/brain/tts/tacotron2/train`
   - `vi hparams.py`
     - 21번째줄에 써있는 포트번호 확인 (현재40001)
     - 위의 포트번호가 사용중인지 확인
       - haparams.py 실행중인것 밖으로 나와서
       - `netstat -nlpt` 실행 후 포트 사용중인가 확인
       - 사용중 아니라면 계속진행
   - 다시 `vi hparams.py`
     - 29번째줄 `training_files='{경로: aurora/aurora_train.txt}'`
     - 30번째줄 `validation_files='{경로: aurora/aurora_val.txt}'`
     - 31, 32번째줄 언어선택
       - 한국어이기때문에 `lang='kor'`
     - 62번째줄 `speaker=['{말하는사람이름: aurora}']`
     - 108번째줄 `batch_size=8`
       - 이건 원하는데로 바꾸기! 
       - 혜림매니저님은 8로 많이하신다
       - 14로하면 한번에 많이씩 데이터가 들어간다
         - 빠르지만 터지는것 주의
       - 4로하면 쪼개서하지만 자주하는것
   - `cd /home/minds/maum/lib/python/maum/brain/tts/tacotron2/train`
   - GPU를 사용하기위해 몇번이 사용중인지 알아본다
     - `watch -n 1 nvidia-smi`
     - 조금기다리면 GPU사용량 뜨는데 맨아래 몇번이 돌아가는지 뜬다
     - 내가 쓰려는게 사용중이 아니라면 계속 진행
     - 사용중이라면 GPU죽인후 진행(이건 조심하자 누가쓰고잇을지 모른다)
   - 나가는 방법은 `Ctrl+c`
     
   - `nohup python -m multiproc -d {사용하려는 GPU번호:0} -d {사용하려는 GPU번호:1} trainerd.py -c {사용하려는모델 여기서는 baseline모델을 사용했다:2019_09_02_fp16_22k_kor_base_2_178000} --warm_start --hparams=distributed_run=True &`
     - 위의 코드 맨마지막 &를 치면 뭐가 막 안뜨고 깔끔한 shell창 유지 가능
     - 위의 코드 너무 지저분하므로 정리된 것은
       - `nohup python -m multiproc -d 0 -d 1 trainerd.py -c 2019_09_02_fp16_22k_kor_base_2_178000 --warm_start --hparams=distributed_run=True &`
     - GPU를 많이쓴다고 무조건 빨라지는건 어니다!
     - `watch -n 1 nvidia-smi` 명령어로 GPU 돌아간느지 확인 한다!

6. tensorboard에 들어가서 확인해볼 수 있다.

   - `cd /home/minds/maum/logs/tts/tacotron2`

   - `ll` 찍어보면 오늘 만들어진 폴더가 있을거다 그안에 들어가자

   - `cd {오늘만들어진폴더이름: 2020_08_28-173821}`

   - `ll` 찍어보면 에러파일확인할수잇다

     - 돌아가다 죽으면 무슨에러엿는지 확인 가능하다

   - 아예 눈으로 보려면 tensorboard 띄워볼 수 있다.

   - 그전에 tensorboard가 이미 사용중인지(떠잇는지)확인해보자

     - `ps -ef | grep tenso`
     - 따로 떠잇는게 없다면 킨다
       - `nohup tensorboard --logdir=. &`

   - tesorboard 주소를 웹창에 친다(크롬 등)

     - tacotron2 텐서보드주소 `{서버주소:182.162.19.6}:6006/#scalars` 

   - 그러면 위의것들이 돌아가는동안(타코2가 돌아가는동안) 해야할 것이 두가지가 있다

     1. 로그를 적는다(사용한 기록)

        - 파일은 공유 드라이브의 Logs의 tmp2.txt 파일에 작성

        - 양식은 다음과 같다

        - ```txt
          aurora 김혜린    #뭘하는건지 누가쓰고잇는건지(본인)
          T2 emb
          @182.162.19.6 GPU 0~1   #0번부터 1번까지 GPU사용하고 있다는것을 기록
          2020_08_28-173821     # 타코트론 전처리는 이폴더야 를 꼭 적어줘야 다음에 이 숫자가 무슨의미인지 알수잇다.
                                  #이것들처럼 아래것들도 알아볼수만 잇게 남기는 목표!!
          T2 Post-emb
          @182.162.19.6 GPU 0~1
          2020_08_28-182049
          
          wg
          @182.162.19.6 GPU 2~3 
          2020_08_28-174429
          
          tenso
          6007 : t2
          6006 : wg
          
          wav files
          @182.162.19.6
          /home/minds/maum/resources/tts/aurora
          ```

     2. 타코가 돌아가는 동안 Waveglow도 돌린다(동시에한다, GPU여러개쓰고 잇으니 가능)

7. Shell로 돌아가서 `cd /home/minds/maum/resources/tts`

8. `vi config_wg.json`

   - 7번째줄은 체크포인트가 몇씩떨어지게할지정하는것 보통 5000
   - 10번째줄은 남자인지 여자인지 모델 정하는것
     - 남자: 22k_baseline_kor/waveglow_194000_m
       - -> /data1/minds/trained/tts/waveglow/22k_baseline_kor/waveglow_194000_m
     - 여자: `waveglow_226000_kss_kva`
       - -> /data1/minds/trained/tts/waveglow/waveglow_226000_kss_kva 이거고
   - 13번째줄은 경로 적기 예시: `aurora/aurora_train.txt`
   - 23번째줄도 validation파일경로 적어주기: `aurora/aurora_val.txt`
   - 28번째줄의 포트가 다른것이랑 안곂치는지도 확인해본다. (현재40002번 그때그때 다를수 있음)

9. `cd /home/minds/maum/lib/python/maum/brain/tts/waveglow/train`

10. `nohup python distributed.py -d {사용할 GPU:2} -d {사용할 GPU:3} -c config_wg.json &`

   - 위의것 깨끗하게쓰면 `nohup python distributed.py -d 2 -d 3 -c config_wg.json &`

11. `cd /home/minds/maum/logs/tts/waveglow` 에 들어가서 로그확인

    - `ll` 찍어봐서 방금생긴(아마 맨마지막) 파일을 적어준다

    - ```
      aurora 김혜린    
      T2 emb
      @182.162.19.6 GPU 0~1   
      2020_08_28-173821     
      
      T2 Post-emb
      @182.162.19.6 GPU 0~1
      2020_08_28-182049
      
      wg
      @182.162.19.6 GPU 2~3 
      2020_08_28-174429       #여기에 방금 찾은 마지막 파일을 적어준다
      
      tenso
      6007 : t2
      6006 : wg
      
      wav files
      @182.162.19.6
      /home/minds/maum/resources/tts/aurora
      ```

12. `cd 2020_08_28-174429 ` (11번에서 찾앗던 마지막 폴더)

13. `nohup tensorboard --logdir=. --port=6007 &`

    - 이전엔 기본포트엿는데 이번엔 기본못쓰므로(이미쓰고잇으므로) 직접 포트번호 지정
    - 오류주의: 위의 명령어는 꼭 12번의 폴더이동을 하고 해줘야한다

14. waveglow직접확인은 `{서버주소:182.162.19.6}:{포트번호:6007}/#scalars` 

    - `duration` 과 `training.loss`가 잘 나오고있다면 잘 되가는거다!
      - `training.loss` 와 `learing.rate`를 헷갈리지 말자!

15. 또한가지 확인하는 방법은 GPU를 확인해보면된다.

    1. `watch -n 1 nvidia-smi ` 하고 (여기서 1은 1초에한번씩 보여달라는것)
    2. GPU몇번에 뭐가 들어가고있는지 확인해보면 된다.
    3. 만약 GPU가 0%가 되엇다면 (떨어지면) 인풋데이터를 확인해보아야한다
       - 사용할 수 없는 특수문자가 있는지
       - 숫자가 있는지
       - 영어가 있는지
    4. GPU 나가는 방법은 `ctrl+c`

16. 지금까지 한것은 1차학습이었다 이제 2차학습을 시작할것이다 (타코트론2)

17. 2차학습

    1. 서버의(지금은6번에서하니깐 6번서버) `/data1/minds/trained/tts/tacotron2/{타코1차 돌아간결과 생긴폴더:2020_08_28-173821}` 들어가보면 

       - checkpoint_0
       - checkpoint_500이 있을거다
       - 위의 500을 밖으로 뺀다 (로컬)
       - 그후 이름을 바꾼다
         - `checkpoint_500_aurora`

    2. 1차학습돌아가고 있는것을 내린다(끈다)

       1. shell에서`watch -n 1 nvidia-smi `
       2. 돌아가고있는 GPU의 `PID`를 확인
       3.  `kill -9 {PID:13036} {PID:13037}`
       4. `watch -n 1 nvidia-smi ` 다시치고 들어가면 내려간것 확인

    3. `cd /home/minds/maum/lib/python/maum/brain/tts/tacotron2/train`

    4. 아까 1번에서 옮겨서 이름바꾼폴더(`checkpoint_500_aurora`)를 `/data1/minds/trained/tts/tacotron2` 에 다시 옮겨놓는다 ( 아까것을 하나만빼서 이름바꿔서 다시 이동시켜넣는 과정이라 생각하면된다.)

    5. `vi hparams.py`

       - 만약 이 2차학습을 주말에 띄워놓을것이면 이 과정을 진행하면된다.
       - 주말동안 500단위로 checkpoint가 생기면 파일이 너무많이생겨서 용량초과로 떨어질 수 있다.
       - 그래서 단위를 넓혀놓고 주말에 돌아가게 하는 작업
       - 15번째줄 2000으로 수정
       - 29,30번째줄 수정

    6. `nohup python -m multiproc -d {쓸 GPU 번호:0} -d {쓸 GPU 번호:1} trainerd.py -c {쓸파일:checkpoint_500_aurora} --hparams=distributed_run=True &`

       - 깨끗하게쓰면
       - `nohup python -m multiproc -d 0 -d 1 trainerd.py -c checkpoint_500_aurora --hparams=distributed_run=True &`

    7. `cd /home/minds/maum/logs/tts/tacotron2`

    8. `ll` 확인하면 방금생겨난 맨마지막폴더를 로그에 적어 놓자

       - ```
         aurora 김혜린    
         T2 emb
         @182.162.19.6 GPU 0~1   
         2020_08_28-173821     
         
         T2 Post-emb
         @182.162.19.6 GPU 0~1
         2020_08_28-182049    # 여기에 두번째 타코트론학습 폴더를 적어준다.
         
         wg
         @182.162.19.6 GPU 2~3 
         2020_08_28-174429       
         
         tenso
         6007 : t2
         6006 : wg
         
         wav files
         @182.162.19.6
         /home/minds/maum/resources/tts/aurora
         ```

    9. tesorboard 들어가서 잘 되고있는지 확인하고 주말동안 결과를 기다린다.

       1. `cd {아까마지막 폴더}`
       2. `ps -ef | grep tenso`
          1. 이전에 1차학습때 켜져잇던 텐서보드를 지운다
             - `kill {1번명령어쳣을때 나오는 맨 앞의숫자 (아마이걸PID라고하는것 같다):13766}`
          2. `nohup tensorboard --logdir=. &`  
       - nohup으로 하는 이유는 컴퓨터 꺼도 알아서 돌아가게 하는 명령어이다.

       - `182.162.19.6:6006/#scalars`

18. **The End!**



#### 결과 듣기

> TTS는 인식률 테스트가 없고, 직접 귀로 들어봐서 가장 좋은 소리를 찾아야 한다.

1. 6번서버를 실행한다 (shell, Filezilla 둘다 내가 학습때 사용했던 서버를 키면된다)

2. `workon waveglow`

3. `cd /home/minds/maum/bin` 

4. Filezilla는 

   - `/data1/minds/trained/tts/tacotron2`
   - `/data1/minds/trained/tts/waveglow` 이 두군데에서 좋은 파일을 찾아 줄 준비를 한다.

5. tensorboard를 킨다

   - Tacotron2는 `http://182.162.19.6:6006/#images` 
     - 여기서 alignment 가 가장 일자인것이 잘 나온것이다
     - 가장 잘 나온것의 파일 명을 기억한다
     - Filezilla에서 그 파일의 파일명 뒤에 `_aurora` 처럼 화자를 달아준다
       - `checkpoint_6000` -> `checkpoint_6000_aurora`
   - waveglow는 `http://182.162.19.6:6007/`
     - 위의 것은 waveglow가 만든음성
     - 아래 것은 진짜음성 (맞춰야하는 음성)
     - 위의 두개가 가장 비슷한 것의 checkpoint를 기억한다
     - Filezilla에서 그 파일의 파일명 뒤에 `_aurora` 처럼 화자를 달아준다
       - `waveglow_540000` -> `waveglow_540000_aurora` 

6. 이제 다시 shell로 가서(혹시새로하는거면 `workon waveglow`)

   - `brain-tts dev`

   - `brain-tts-rest dev`

   - ` python brain-tts-tacotron2 -m /data1/minds/trained/tts/tacotron2/2020_08_28-182049/checkpoint_6000_aurora -d 0 -s 1500 -t 0.01 -p 30101 &`

     - 위의 코드는 python brain-tts-tacotron2 -m {장소/가장좋은 타코트론} 옵션값 & 로 생각하면 된다 

   - `python brain-tts-waveglow -m /data1/minds/trained/tts/waveglow/2020_08_28-174429/waveglow_540000_aurora -s 0.666 -ds 0.01 -d 1 -p 35101 &`

     - 위의 코드는 python brain-tts-tacotron2 -m {장소/가장좋은 웨이브글로우} 옵션값 & 로 생각하면 된다 

   - 위의 옵션값들은 다음과 같다

     - | 모델   | tacotron2   |            | waveglow               |            |
       | ------ | ----------- | ---------- | ---------------------- | ---------- |
       | 옵션값 | s: 잡음조절 | t          | s: 안정성              | ds: 기계음 |
       | 높으면 | 안녕하세요~ | 0.01(고정) | 울린다(동굴소리)       | 금속소리   |
       | 낮으면 | 안녕        | 0.01(고정) | 깔끔하지만 안정성 감소 | 먹먹함     |
       
     - 상세설명
     
       - tacotron2
     
         t가 낮은 경우 - 말이 다 나오지 않음(문장을 다 만들지 못함)
     
         t가 높은 경우 - 말이 다 나오고 나서도 음성이 끝나지 않고 이상한 말이 나옴
     
         s가 낮은 경우 - 음성의 길이가 s*256 / 22050초(-s 1600 기준 약 18초)이면서 말이 다 나오지 않음
     
         s가 높은 경우 - 음성의 길이가 s*256 / 22050초일 때, GPU의 RAM이 
     
       - waveglow
     
         s가 낮은 경우 - 특정 주파수의 소리가 생김, 전반적으로 먹먹한 느낌이 생기며, 음성의 안정성이 낮아지나(목소리가 떨리는 등), 울리는 소리가 감쇄됨
     
         s가 높은 경우 - 전반적으로 음성의 안정성은 높아지고 선명해지나, 울리는 소리가 생김
     
         ds가 낮은 경우 - 소리는 명료하나, 특정 주파수의 소리와 지저분한 소리(금속음, 풍절음 등)가 남아 있음
     
         ds가 높은 경우 - 특정 주파수의 소리와 지저분한 소리(금속음, 풍절음 등)가 지워지지만, 소리가 약간 먹먹해짐
     
     - 기본값
     
       - taco2: -t 0.1, -s 1600
       - wg: -s 0.666 -ds 0.01

7. `http://182.162.19.6:9998/tts-rest/` 를 들어간다 (고른 taco와 wav 를 섞어서 직접 들어보는 것)

   1. 원하는 스크립트를 친다

      - 하지만 권장하는 스크립트 있다.
      - 공유드라이브 - Working - KL 의 **TTS결과값확인스크립트** 의 문장들을 사용하면 더욱 좋다
2. 아래의 `Go` 나 `Preprocessing` 을 누르고 기다린다
   
   - 긴 스크립트일수록 오래걸린다
   3. 나오는 소리를 들어보고 소리가 괜찬으면 파일을 저장

      - 파일 명

      - taco2 체크포인트, 옵션 값
   - waveglow 체크포인트, 옵션 값
      - 위의 3개를 저장해두면 다른 값들과 비교하기 좋다
   4. 소리가 마음에 들지않으면 taco2와 waveglow 파일을 바꿔가며, 옵션값을 바꿔가며 최적의 소리를 찾는다
      1. 이때 `ps -ef | grep brain` 을치면 방금전에 올린 명령어가 잇을거다
   2. 여기서 PID확인한 후에 kill 해주고 새로띄워줘야한다 
   
8. **The End**!



#### API 넘기기

> 위의 모들 과정이 끝나면 어떠한 서버에 띄워서 듣고 API정보를 연동시키고, 연동된 API 정보를 전달하는 과정이 필요함.

1. Shell 6번서버 켜기

   1. `workon waveglow`

   2. `cd build`

   3. `cd waveglow`

   4. `cd remake`

   5. 이곳에 가장 좋은 결과였던 waveglow파일을 복사한다.

      - 이것은 cp명령어를 사용하면 편하다
      - `cp {옮길파일위치/이름} {옮겨질파일위치/이름}`
      - 예시로 `cp /data1/minds/trained/tts/waveglow/2020_09_15-121139/waveglow_250000_dubu /home/minds/build/waveglow/remake/waveglow_250000_dubu`
      - 옮겨질 위치에서 이름 바꾸면 바뀐 이름으로 복사된다.

   6. 다옮겨진 후에 `./a.sh` 실행

      - 완료 되었다면 해당 파일 뒤에 `_re` 가 붙은 파일이 생긴다
      - 예시로 `checkpoint_240000_dubu` 였으면 `checkpoint_240000_dubu_re` 가 생길 거다.
      - taco말고 waveglow 파일만 _re로 붙이는거 맞는거니 당황 ㄴㄴ

   7. `_re` 파일이 생성 되었다면 `https://docs.google.com/spreadsheets/d/19fMDRfE4o79EPsw3-ASDSqqDzL2twaxK8vfgdm7060Q/edit#gid=0` 이곳에 들어가서 나의 가장 좋았던 taco2 와 waveglow의 `파일명`, `파라미터`모두 적어놓는다

      - 이때 waveglow는 `_re` 파일임을 잊지말자

   8. 그럼 이제 해당 taco2, waveglow 파일들을 101번서버에옮겨놓는다.

      - `/home/mindslab/model` 이 위치에 타코는 타코에 웨글은 웨글에 옮겨놓으면 된다.

   9. 다 적었으면 적은 부분을 캡쳐해서 tts-ten 방의 `오세진 대표`님께 슬렉드린다.

      - 양식

      - ```
        안녕하세요. 오세진 대표님,
        스트리머 연두부 모델 추가 부탁드립니다.
        {캡쳐사진}
        ```
        
      - ![image](https://user-images.githubusercontent.com/60081254/95424536-be1bff80-097d-11eb-8e30-821740b15200.png)

   10. 오세진 대표님께서 포트번호를 주시면 4가지항목을~~유종호 매니저~~ -> `박지호 이사님`님께 드린다!

       >  유종호 매니저 -> **박지호 이사**님으로 바꼇음!
   
       - 드릴 항목과 예시
         - 모델있는 서버  `114.108.173.101 서버`
         - 포트번호   `30802`
         - 모델명  `dubu`
         - 화자 `0`번
           - 여기서 화자는 몇명이 말햇는지를 의미
        - 만약 3명이 발화한 것이면 0,1,2이므로 `2`를 적으면 된다.
       - ![image](https://user-images.githubusercontent.com/60081254/95424592-d12ecf80-097d-11eb-995a-cad91a5e57cd.png)

       - 저기서 `dubu 모델을, ejn, ju~~` 여기는 dubu님의 회사이름이 ejn이기때문에 한 것. 모르겠으면 혜린매니저님께 문의

       

   11. 해당 api에 연동이되면
   
       - 직접인텔리제이로 DB에 들어가서 두부님만 사용할 수 있는 아이디 페스워드만들어야한다.
    - 만들어서 샌드박스에 ID PS를 전달해준다 
         - (메일로 : 안녕하세요 마인즈랩~ ~ ~이규민입니다. 어찌구저찌구 불안정한 부분은 추후 개선 가능하오니 ~ ~ 주시기 바랍니다. 감사합니다.)

   12. 마지막 팁!
   
       - 특정 날짜까지 메일을 전달할거면 적어도 하루전까지는 모든걸 끝내놔야한다.
       - 만약 이모든 과정의 어떠한 담장자가 휴가인 경우나 갑자기 무슨 기능이 안되면 계약 날짜를 맞추지 못한것이니 미리미리 해놓자!




#### API 연동 확인

> Postman을 사용한다.

- postman 사용법은 이규민 작업공간에서 `Postman 사용가이드`를 참고하시오

- ```
  "apiId" : "juho-minds-api",
  "apiKey" : "62fd4f9c135644f3935c4beb0f933018",
  ```

- 위에꺼에 스프레드시트에 써논 Voice 이름만 바꿔서 사용하자
- **대소문자 주의!**



**TTS 진짜끝!!**



### :three: 기타 정보

#### TTS, STT 제작 비용

TTS 는 따로 개발할 것이 없으므로 계약시작부터 매달 돈을 내면된다

- Shared 서버: 매달 27만원
- dedicated 서버: 매달 63만원

- 대신 녹음실 비, 성우 섭외비는 직접 내셔야 한다.

STT는  따로 개발이 필요하므로 개발 비를 내야한다

- 개발과정에서는 매달 500만원(3~6개월)

- 유지보수에서는 금액 새로 측정해야한다.

  - revenue share
  - api 사용량에 따른 재 논의

  

#### TTS, STT revenue share

revenue share에 계약서들은 `\AICS Dept\Muse\2. Documentation\Streamer` 여기에 있다!

- 개인이 계약할때는 `귀사명` 에 해당하는것을 다 지우면 된다.

- revenue share 비율은 다음과 같다

- | 상황                  | Default<br />(샌드박스는여기) | 소개없이 개인적으로<br />바로 연락온 경우 | 소개는 받았지만 <br />소속사가 없는경우 |
  | --------------------- | ----------------------------- | ----------------------------------------- | --------------------------------------- |
  | TTS 요금              | A                             | A                                         | A                                       |
  | 시스템비용<br />(EJN) | A * 17.5%                     | A * 15                                    | A * 20                                  |
  | 귀사명(소속사)        | A * 5%                        | A * 5                                     | A * 0                                   |
  | 스트리머성명          | A * 50%                       | A * 50                                    | A * 50                                  |
  | 엔진사비용(마인즈랩)  | A * 27.5%                     | A * 30                                    | A * 30                                  |

  



#### TTS 녹음 갈때 참고

> 레벨나인 스튜디오
>
> 01045577038

- 문의 시 `김혜린 매니저와 함께일합니다` 라고 소개 반드시 할것

  - 나중에 세금계산서를 한번에 받기 위함
- 스튜디오는 A,B룸이 있다 (우리는C룸은 사용하지 않음)
  - A룸: 스트리머 분들 오실 때 사용
  - B룸: 성우분들 녹음하실 때 사용
- 소속사가 있는경우 담당하는 팀장님이나 매니저가 나올거다
- 소속사가 없으면 개인이 나올거다
- **녹음날 계약서를 다 작성해서 가져가**야 등기로 왓다갓다 안하고 편하다
  - 이건 3자 계약을해야해서 왓다갓다 많이해야하니깐 이때 하는게 편하다
  - 계약서 가져가는 방법
    - 프린트한다
    - `AICS Dept\Muse\1. Admin\Invoice` 에 있는 **invoice 파일을 표지로 동봉**한다 !
    - 스테이플러찍지말고 집게 클립으로 묶는다
    - 투명화일에 넣는다
    - 등기봉투에 넣는다
    - 녹음날 준다
- 만약 계약서를 서로 등기로 왓다갔다해야하면 아래를 참고하자
  1. 만약 3자계약이라면 계약서를 3부를 출력한다
  2. 좌측부터 갑을병 3부를 놓고 각 문서사이에 모든페이지에 사이간인을 한다
  3. 모든페이지마다 반절씩 접어서 모든페이지 사이에 사이간인을 한다
  4. 서명한는곳(보통계약서 마지막)에는 `스트리머 녹음일`을 기준으로 서명일에 날짜를 적는다
  5. 도장 다찍은 파일은 클립(납짝한거) 을 각각찍는다
  6. 투명화일에 넣는다
  7. 보내는곳 주소를 프린트한다(크게)
  8. 짤라서 종이봉투(마인즈랩봉투)에 받는분에 붙인다
  9. 내용물 넣어서 동봉한다
  10. 심나리 매니저님(재무팀)께 등기보내려고 법인카드 부탁드린다
  11. 지하1층 오른쪽가면 우체국 있다 거기가서 보낸다
  12. **영수증 꼭 가져온다**
  13. 인사팀 뒤쪽 법카 폴더있다 그거 꺼내서 영수증 넣어놓고 법인카드 사용대장 작성한다
      - 이때프로젝트코드알아야하므로 알아간다
      - 카드는 아직 반납하지말자 카드 맨 뒷번호 써야한다
  14. 다하고 심나리매니저님께 반납하면 끝이다 수고했다.





## ------------------------------------

## * 유용한 IT 지식들

> 당신이 IT업계에서 살아남고 싶다면 알아둬서 나쁠 것 없는 것들입니다. (사실 내가 몰라서 만듬)
>
> `data` `bigdata` `docker` `ai` `linux` `rpc` `DL` `ML`

### :one: Docker

> 도커환경에서의 TTS 학습을 연습이므로 꾸준히 업뎃될 예정입니다.. (2020 10.05~ 현재 진행 중)
>
> 1. https://pms.maum.ai/confluence/pages/viewpage.action?pageId=25695639 의 TTS in docker를 참고하여 만들어진 문서 입니다. (윤서영 매니저님 컨플)
> 2. 도커에대한 자세한 용어정리는 https://subicura.com/2017/01/19/docker-guide-for-beginners-1.html 여기가 아주 좋다! (`image`, `container` 등...)
> 3. 컨플루엔스 - 실무교육 -cli기초 - linux docker 공부하기
>
> ```txt
> 현재 6, 9번서버에 TTS 사용을 위한 Docker 환경 구축 계획입니다. 환경구축이 완료되면  6번 서버의 /home/minds/maum/trained/tts/waveglow 의10.05일자 waveglow 파일이 있다 활용하여 도커환경에서 돌리기 연습을 해야합니다.
> ```
>
> 

기본적으로 TTS 엔진은 아래 사진과 같은 형태로 돌아가게 됩니다.

![image](https://user-images.githubusercontent.com/60081254/95424614-dbe96480-097d-11eb-9963-cb87187f23c3.png)

#### Docker 기본 환경 SET

> 윤서영 매니저님 컨플: https://pms.maum.ai/confluence/pages/viewpage.action?pageId=25695657
>
> Docker 개념정리: https://cultivo-hy.github.io/docker/image/usage/2019/03/14/Docker%EC%A0%95%EB%A6%AC/#sudo-%EC%97%86%EC%9D%B4-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0
>
>
> 이제는 taco 가 아니라 https://pms.maum.ai/confluence/display/audio/TTS 에서 알려주는 DCA로 한다.

- docker 권한주기
  - `sudo usermod -aG docker $USER`   현재 접속중인 사용자에게 권한 주기 (이거쓰삼)
  - `sudo usermod -aG docker your-user`  ypur-user 사용자에게 권한주기 (이거사용 할일잇을까?)

- docker 켜기
  - `sudo systemctl start docker`

- docker image 받기
  - tacotron2:  `docker pull docker.maum.ai:443/brain/tacotron2:1.2.7-server`
  - waveglow: `docker pull docker.maum.ai:443/brain/waveglow:1.2.7-server`
  - grpc: `docker pull docker.maum.ai:443/brain/tts:1.2.7-server`
- 다운받은 도커 이미지를 보는 명령어
  - `docker images`
- 도커 이미지를 삭제하는 명령어
  - `docker rmi {이미지 ID}`

#### Docker TTS 학습

- tacotron2 컨테이너 생성
  - `docker run -itd --ipc host --gpus '"device=**0,1**"' -v **/[DATA1:/DATA1](http://data1/DATA1)** -e LC_ALL=C.UTF-8 --name **taco_train** docker.maum.ai:443/brain/tacotron2:1.2.7`
  - docker run {옵션} {이미지 이름} {실행할 파일} 형식
- waveglow 컨테이너 생성
  - `docker run -itd --ipc host --gpus '"device=**0,1**"' -v **/[DATA1:/DATA1](http://data1/DATA1)** -e LC_ALL=C.UTF-8 --name **wg_train** docker.maum.ai:443/brain/waveglow:1.2.7`

- 생성한 컨테이너 목록 출력```````````````````````````````````````````

  -  `docker ps -a`

- 기타 기본적인 정보 밑 명령어

  - docker 환경에서 뭔가 안되면 `sudo` 명령어를 맨앞에 붙여서 해보자 sudo = super do 로 관리자 권한 실행이다.

  - docker 의 컨테이너를 지우기 위해서는 컨테이너를 중지 시킨 후 삭제할 수 있다.

    - `docker stop hello`  :hello 라는 컨테이너를 중지
- `docker rm hello` :hello 라는 중지된 컨테이너를 삭제
    - `docker inspect {ID 또는 name}`  :image 또는 container의 세부 정보 출력
- `docker start hello` : hello 라는 중지된 컨테이너를 켜는것

#### 



### :two: Linux

> 당신이 리눅스 환경이 익숙치 않다면 아래 명령어만 익혀도 전혀 문제가 없을 것 입니다. (2020.10.08 작성 미완료)

- ls

  > 현재 위치의 파일 목록을 조회

- cd

  > 

- touch

  > 

- mkdir

  > 

- cp

  > 

- mv

  > 

- rm

  > 

- cat

  > 

- redirection

  > 

- alias

  > 



### :three: RPC

- 어떠한 서버에서 API를 받아와서 사용하고자 한다.
  - 우리는 API Document의 사용법만 확인하여 순쉽게 구현이 가능하다
- 하지만 **현실은** `네트워크`, `서버`, `클라이언트` 등 각종 문제가 발생할 수 있다.
- 그 모든것을 개발자가 직접 다 컨트롤하려면 힘들기 때문에 등장한것
  - **RPC**
  - 즉, RPC는 `Server`에 있는 프로그램 정보를 알고있는 `IDL(Interface Definition Language)`를 활용해서 개발자는 네트워크, 통신 등과 관련된 작업은 신경 쓰지 않아도 되고, **원격지에 위치한 프로그램을 로컬에 있는 프로그램 처럼 사용** 할 수 있습니다.
- gRPC: 구글에서 개발한 RPC
- 결론: 좋은거다 짱짱맨

### :four: REST

- 웹에서의 일종의 **스타일**을 의미
  - `Http 1.1`을 사용하며
  - url을 자원(resource)로 표현하고
    - url에 동사없이 명사로만 구성을 해야 한다.
      - ex) http://www.o.com/user/summy/profile/address 이런식
  - 처리결과를 Status Code로 사용한다
    - 기존에는 http의 처리 결과를 header의 Status Code는 200으로, 처리결과는 body에 작성
    - 하지만 RESP에서는 처리 결과를 header의 Status Code를 활용한다.
- 이러한 REST가 제안하는 스타일에 맞는다면
  - **RESTful 하다** 라고 말합니다.

## ------------------------------------

## *사업 현황

### STT

#### 삼성영어

> 하단의 문서는 이예준 팀장님께 배운 내용을 정리하였습니다.

삼성영어 서비스 구조	

* ![image](https://user-images.githubusercontent.com/60081254/95424675-f4597f00-097d-11eb-925f-145710402016.png)

##### ISSUE

1. CNN-STT를 사용 중인 서버의 메모리 누수현상

   > 서버정보
   >
   > STT4: 119.207.75.53 / STT5: 119.207.75.54

   * 메모리 누수가 나고 있는 부분을 찾는 과정 필요
     * 메모리 누수를 찾고 그부분을 고친 후, 따로 메모리 감소문제 발생하지 않으면 타 과정 진행 하지 않아도 됨
   * 메모리 누수 나는 부분을 발견 하지 못하는 경우or 관리가 어려운경우 아래 과정 필요
     * 정기적(매일 새벽 3시)으로 서버리부팅 및 엔진이 자동으로 뜨는 자동화 스크립트 생성 및 실행

2. 서버 or 엔진에 이상이 있는경우 알림 기능

   * STT 1, 2, 3, 4, 5 다섯개 서버와 각 서버의 엔진에 이상이 생겨서 STT 변환이 원활하지 않을 때, 이메일,카카오톡, 사내SMS 등 알림이 가는 기능 구현 요청
   * 삼성출판사 내부적으로 보유중인 메일 서버는 없으며, 메일 수신만 가능한 클라우드 메일서버만 있음
   * 사내 SMS는 현재 뿌리오 (다우기술) 사용중
   * **Slack, Telegram 등 무료로 진행할 수 있는 메신저가 있다면 해당 메신저 사용해도 됨** 



3. 삼성출판사의 추가학습 요청시 데이터 추출
   * 연2회 정기 추가학습 + 단발성 추가학습 요청이 있을 예정.
   * 이때 필요한 학습데이터 추출 작업 지원



##### 서버 접속 정보

**삼성영어 서버에 대한 접속정보**는 아래와 같음.

- ![image](https://user-images.githubusercontent.com/60081254/95424717-076c4f00-097e-11eb-95bf-b9f2e4c392f7.png)



##### 서버&엔진 재부팅 프로세스

> 삼성출판사에서 특정 문제가 발생(엔진이꺼짐, 서버가 내려감 등) 하면 아래의 작업을 통해 서버를 리부팅, 엔진을 살려주고 있습니다.

###### 1. DNN-STT

> 현재 STT 1, 2, 3 서버가 DNN-STT 사용 중

1. STT 1, 2, 3 중 작업할 서버에 접속

2. 경로이동(서버마다 경로가 다름)

   * STT 1: `cd $MAUM_ROOT`
   * STT 2, 3: `cd /srv/maum`

3. `cd bin`

4. `svd`

5. `svctl`

6. `status` 로 상태 확인

   * 이때 brain-stt, english-evaluation-server, phonics 3개 엔진이 켜져있어야하며 
   * 만약 안켜져있는게 있으면 `start brain-stt` 처럼 start {엔진} 으로 키면된다.

7. `netstat -nlpt` 를 쳐보면 아래처럼 떠있어야한다

   * ![image-20210216142344700](https://user-images.githubusercontent.com/60081254/112247722-26df0600-8c98-11eb-9ace-a700175739ef.png)

8. 근데 아마도 stt wps와 stt dialog 라는건 안켜져 있을 수 있다. 시간이 좀지나면 (1분정도?) 알아서 자동으로 켜지긴 할건데 그 사이에 직접 켜주고싶다면 아래의 과정을 진행하자. 

   1. 경로 이동
      * STT 1 서버는 경로가 다르다: `cd /data1/maum/trained/stt`
      * STT 2,3은 `cd /srv/maum/trained/stt` 
   2. 모델띄우는 명령어 실행
      * sttcli -m {모델명} -lang eng -r 16000 start 
      * wps : `sttcli -m wps -lang eng -r 16000 start`
      * dialog : `sttcli -m dialog -lang eng -r 16000 start` 
      * 이때 모델명을 full name  쓰는게 아니라 wps, dialog 처럼 앞글자만 써야된다.

9. DNN-STT 잘되고 있는지 로그를 확인한다.

   1. 경로 이동
      * STT1: `cd /data1/maum/logs`
      * STT2, 3: `cd /srv/maum/logs`
   2. 명령어 실행
      * `sudo tail -f brain-sttd.log`

10. 끝

    > 혹시라도 엔진들이 알아서 안뜨면 아래를 하자 

    1. Phonics 엔진 실행방법
       * 경로`cd /home/minds/msl.service/phonics/bin	`
       * `./phonics_eval`
    2. 발음평가 엔진 실행방법
       * 경로이동 
         * STT1경로 `cd /data1/english-evaluation-server/bin`
         * STT2, 3 경로  `cd /srv/english-evaluation-server/bin`
       * `./start.sh`

###### 2. CNN-STT

> 현재 STT 4, 5번 서버가 CNN-STT 사용 중이다

1. STT4, 5 중 작업할 서버에 접속

2. `sudo systemctl start docker`

3. `sudo systemctl enable docker`

4. `docker ps -a` 해서 w2l_samsung_103 이켜져잇는지 보자 꺼져잇다면 아래 명령어 실행

   1. `docker start w2l_samsung_103`
   2. 다시한번 `docker ps -a` 해서 켜졌는지 확인

5. `docker exec -it w2l_samsung_103 bash`

6. `nohup ./Server --flagsfile /MODEL/server.cfg &`

   - 혹시 위에꺼가 안되면 경로가 도커 안에서, `~/wav2letter/build` 가 맞는지 확인

7. `exit` 명령어로 docker 밖으로 나감.

8. `workon venv_vad`

9. `cd /srv/maum/bin/brain-vad/brain-vad`

10. `nohup ./server.py &`

11. `cd /srv/maum/bin/brain-vad/cnn_proxy`

12. `nohup ./cnn_proxy -port 9802 -remote 127.0.0.1:15001 &`

13. `./sttcli -host 127.0.0.1:9802 -s stream 0019_20191202150930_111.wav`

    - 이 명령어를 쳤을때 stream closed()나오면 성공!! 

14. `sudo netstat -nlpt` 명령어로 cnn_proxy 떠있는지 확인하자

15. 지금까지 한건 아래 4개중에 한개 킨 것. 이제 나머지를 띄워보자

    | port 번호 | 너가 띄울거                          |
    | --------- | :----------------------------------- |
    | 9802      | ~~cnn_proxy 방금까지 띄운게 이거다~~ |
    | 15001     | cnn_stt 엔진                         |
    | 9993      | 발음평가                             |
    | 10101     | 파닉스엔진 phonics_eval              |

16. `deactivate`로 가상환경을 나온다

    2. `cd $MAUM_ROOT/bin`
    3. `./svd`
    4. `./svctl` 이거를 쳣을때 아래 두개가 running이라고 뜨면 다 된거다!
       - english-evaluation-server
       - phonics
         - (brain-stt는 Stopped여도 된다)
    5. 아래 두개 명령어는 필요할지 모르겠으나 언제필요할지 모르니 메모해둠
       - 발음평가 엔진 재시작 : `/srv/english-evaluation-server/bin/start.sh`
       - 파닉스 엔진 재시작 : `/home/minds/msl.service/phonics/bin/phonics_eval`

17. 끝



##### Web 서버 재부팅

> 하단의 내용은 이예준 매니저님께 여쭤본 내용으로 실제 진행을 한 적은 없습니다.
>
> 가능한 Web 서버 재부팅은 하지 않는 것이 좋다. 
>
> 하지만 굳이 할일 이 있으면 아래의 Step을 따라가자
>
> 삼성영어 Web 서버는 3개가 있다. 하지만 현재 Web1, 2, 3 중 1, 2 만 사용 중이다
>
> Web 3은 환경 구축이 되었으나, 사용이 안되고 있다.(왜안될까...)

1. 서버정보

   * 모든 서버 접속자: `minds` 비밀번호: `msl1234~`

   * Web1 119.207.75.40
   * Web2 119.207.75.41
   * Web3 119.207.75.42

2. 재부팅 
   1. 재부팅은 하던데로 `sudo reboot` 
   2. 경로 이동 `cd /home/minds/auto.start`
   3. 명령어 실행 `./webstartup.sh`
      * 이 파일은 누군가 재시작을 위해 만든 스크립트 파일로 vi 명령어로 보면 이것저것 켜지게 한다.
3. 끝



##### STT 변환 속도테스트

> STT 변환 속도에 대한 실행 코드 및 테스트 결과

###### 1. DNN-STT 

> 아래의 두가지 코드 중 한가지를 실행하면 된다.
>
> 실행 위치는 어느곳에서든지 상관없다.

```
sttcli -m wps -lang eng -r 16000  -s stream 0019_20191202150930_111.wav
sttcli -m dialog -lang eng -r 16000  -s stream 0019_20191202150930_111.wav
```

* -m : 모델명 wps, dialog
  -lang : 언어
  -r : 샘플레이트
  -s : 스트리밍 방식 설정

  파일 :0019_20191202150930_111.wav

**테스트 결과**

> 2021.02.05 결과

**STT 1**

* wps
  * 1차 - 0.244980
  * 2차 - 0.248472
  * 3차 - 0.238741
  * 평균 0.244064
* dialog
  * 1차 - 0.246647
    2차 - 0.194332
    3차 - 0.211383
    평균 0.217454

**STT 2**

* wps
  * 1차 - 0.197212
  * 2차 - 0.216701
  * 3차 - 0.200624
  * 평균 0.204845
* dialog
  * 1차 - 0.185422
    2차 - 0.188280
    3차 - 0.195622
    평균 0.189774



**STT 3**

* wps
  * 1차 - 0.238956
  * 2차 - 0.242996
  * 3차 - 0.213294
  * 평균 0.231748
* dialog
  * 1차 - 0.192659
    2차 - 0.209305
    3차 - 0.183887
    평균 0.195283



###### 2. CNN-STT 

> 아래의 코드를 /srv/maum/bin/brain-vad/cnn_proxy 에서 실행
>
> ./sttcli -host 127.0.0.1:9802 -s stream 0019_20191202150930_111.wav

**STT 4**

* 1차 - 0.107293
* 2차 - 0.089371
* 3차 - 0.094772
* 평균 0.097145



**STT 5**

* 1차 - 0.089988
* 2차 - 0.177245
* 3차 - 0.101926
* 평균 0.123053



##### 삼성출판사 Test page

> STT 변환, 평가엔진 등이 잘되고있는지 확인해 볼 수 있는 Testpage

* DNN-STT: https://119.207.75.34:8080/uapi/Phonics.html

* CNN-STT: https://119.207.75.34:10080/uapi/Phonics.html

* 위의페이지들에서 `파닉스 평가` 를 눌러서 테스트해보자.

##### 데이터 추출하기

> 41번서버에서 추출하면되고 모르면 예준매니저님께 질문!

1. 41번 서버에 



### TTS

#### 스트리머 TTS 수입 확인

> 스트리머한테 돈이 얼마씩 들어오고 있는지 확인 할 수 있다. DB를 알고 SQL할줄알면 좋을걸?
>
> 참고 할 것 
>
> ```
> https://pms.maum.ai/confluence/display/~hwern@mindslab.ai/EJN-log-viewer
> 내용1 : https://twip.kr/api/get_myvoice_log?apiKey=5c16f9dfea3afa8e8b0e59f99b2d0bef7d8921db
> 내용2 : 182.162.19.9:32796 (DB : mysql // ID : root // pw : ejnahc)
> 내용3 : 서버접속권한 182.162.19.9 (ID : minds // pw : msl1234!)
> ```

1. **MySQL WorkBench**를 깐다.

   * 아마 깔면 뭐 C++ 2019 for Visual Studio 이런거 필요하다고 할텐데, 해당 되는걸 깔면된다, (구글링하면 다나옴)
   * 기억안나서 링크 첨부못햇다 ㅈㅅ

2. **MySQL WorkBench** 키고 위에 창에 Database 누르고 connect to database 눌러서 서버 연결하자

   - hostname : 182.162.19.9
   - port : 32796
   - Username: root
   - pw: ejnahc

3. 들어오면 왼쪽에 많은 Schma 들이 보일 거다.

4. 우리가 이제 할 것은

   1. 고객(목소리주인)이 편하게 자기 목소리 확인해볼 수 있도록 페이지 DB에 계정추가(권한추가)
   2. 그 계정 DB에 재생할 수 있는 목소리 추가
   3. 스트리머 DB에 목소리 주인 추가 (필수)
   4. 추가된 스트리머를 정산 page DB에 추가이다 (필수)

   필수인 것은 필수이고 나머지 두개는 그렇게 안하면 POSTMAN으로 하면 된다.

5.  4-1 4-2 수행

   1. moddle_tts_test 에서 Tables 에서 USER 테이블에 우클릭해서 Select rows 클릭하자.
   2. 거기에 만들어주고싶은 id 와 key, user_pk를 입력하자
   3. moddle_tts_test 에서 Tables 에서 ACCESS_MODEL_DEV 테이블 우클릭 select rows 하자
   4. 거기에 아까 만든 id를 그대로 갖고온다. 그리고 추가원하는 모델(TTS API VoiceName)을 추가한다. pk는 알아서 써라
   5. 그럼이제 너는 고객에게 목소리 들어보세요 계정은 ~ 비번은 ~로 하시면되요 할수 있다. 페이지 주소는
   6. `G:\.shortcut-targets-by-id\18zpKMjMbPxjSWchPmR53F2ZoTNC28qvZ\AICS Dept\Muse\7. Sent\20200219_API Test Page` 여기 경로에 있다. 경로는 알아서 찾아가라 저건 내기준 ㅠ
   7. 저 페이지 공유드리고 로그인해서보세요 ~하자

6. 4-3 4-4 수행

   1. ejn_log 에서 tables 에서 Streamer_info 열자 (우클릭)
   2. 위에 보이는 SQL구문에서 너가 찾기원하는 스트리머를 찾는다
      * ` select * from ejnlog.STREAMER_INFO where Streamer_name="";`
      * 위의 Streamer_name은 트위치에서 스트리머 id 찾으면댄다
      * 본인이 SQL 잘하면 Like 구문을 쓰면 댄다.
   3. 그렇게 스트리머 찾아서 STREAMER_ID를 찾아서
   4. VOICES 테이블에 아까 찾은 STREAMER_ID로 추가해주고 해당 스트리머 계약서에 명시한 비율대로 오른쪽에 비율을 써놓자
   5. 완료

7. 정산 되는것 확인해보자 링크는 아래와 같다.

   * http://182.162.19.9:5001/auth
   * id: minds
   * pw: msl1234!

8. 끝!





- 

## -----------------------------------

## * 업무환경 세팅

> 처음에 회사에오면 당황스럽겠지만 서버?계정? 모르는게 많을때 큰 힘이 되어줄 것입니다.

### maum.ai 계정(구글)

- ID: `lkm@mindslab.ai`
- PW: `941219asd!`

### Server

- NAS 서버

  > 윈도우키 + R 눌러서 주소 입력후 open

  - 주소: `\\10.122.64.181` 
  - ID: `datateam` PW: `data2019!@#`

- 6번

  > Filezilla를 통해 open
  >
  > new site누른후 프로토콜 sftp 로 변경 후 아래의 주소들 진행
  >
  > 6,7,9 동일

  - 주소: 182.162.19.6
  - ID: `minds` PW: `msl1234!`

- 7번
  
  - 주소: 182.162.19.7
- ID: `minds` PW: `msl1234!`
  
- 9번
  
  - 주소: 182.162.19.9
- ID: `minds` PW: `msl1234!`
  
- ~~12번(?)~~
  
  - ~~주소: 182.162.19.12~~
  - ~~ID: `minds` PW: `msl1234!`~~

- 101번
  
  - 호스트: 114.108.173.101
  - ID: `mindslab` PW:`ml142314`

### VPN

> Maum이 아닌 다른 와이파이를 사용하는 경우 항상 VPN이 필요하다

- Hillstone Secure Connect 프로그램 연결
- Server: `125.132.250.203`
- Port: `4433`
- Username: `lkm`
- PW: `lkm1234!`



### 공유드라이브

- 날짜+간단한내용 으로 폴더만들고
- 내용이되는 어떤 파일은만들때 {날짜}{간단한내용}_{v1}버전을 써준다! 
  - 수정받고 v2 이렇게 올린다.
- 프린트하는것은 vf 프린트안하고 보내는것은 vs를쓴다
- pptx나 excel파일은 pdf로 바꿔서 꼭 올려준다(원본도포함)
- 엑셀의경우영역드레그 페이지레이아웃 인쇄영역-인쇄영역설정
  미리보기는 보기-페이지나누기 미리보기



### 프린트

- 프린터는 인프라팀에 문의해서 연결하도록한다
- 엑셀을 프린트할때 
  - sheet가 여러개면 각 페이지마다 단면or양면을 따로 지정해준 후 
  - 한번에 인쇄하면 아마 하고있는 고민이 풀릴 것이다.



### KBS TTS TOOL

> 함부로 사용하지마라 진심이다

https://kbs-tool.maum.ai/?#/login


